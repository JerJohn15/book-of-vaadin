<?xml version="1.0" encoding="UTF-8"?>
<!-- ====================================================================== -->
<!-- Copyright 2000-2012 Vaadin Ltd                                         -->
<!-- All Rights Reserved                                                    -->
<!-- This work is licensed under a Creative Commons Attribution-NoDerivs    -->
<!-- License (CC-BY-ND) Version 3.0. Full license text is available at:     -->
<!-- http://creativecommons.org/licenses/by-nd/3.0/legalcode                -->
<!-- ====================================================================== -->

<chapter xml:id="testbench">
	<title>Vaadin TestBench</title>

    <para>
        This chapter describes the installation and use of the Vaadin TestBench.
    </para>

    <section xml:id="testbench.overview">
        <title>Overview</title>

        <para>
            Testing is one of the cornerstones of modern software development. Extending
            throughout the entire development process, testing is the thread that binds
            the product to the requirements. Conformance to user scenarios is validated by
            end-to-end acceptance testing. In agile and other iterative development
            processes, with ever shorter release cycles and continuous integration, the
            automation of integration, regression, endurance, and acceptance testing is
            paramount. Further, UI automation may be needed for integration purposes, such
            as for assistive technologies. The special nature of web applications creates
            many unique requirements for both testing and UI automation.
        </para>

        <para>
            Vaadin TestBench allows controlling the browser from Java code, as illustrated
            in <xref linkend="figure.testbench.webdriver"/>. It can open a new browser
            window to start the application, interact with the components, for example, by
            clicking them, and then get the HTML element values.
        </para>

		<figure xml:id="figure.testbench.webdriver">
			<title>Controlling the Browser with Testbench</title>
			<mediaobject>
				<imageobject role="html">
					<imagedata align="center" fileref="img/testbench/webdriver-use-lo.png"/>
				</imageobject>
				<imageobject role="fo">
					<imagedata scale="70" smallscale="100%" align="center" fileref="img/testbench/webdriver-use-hi.png"/>
				</imageobject>
			</mediaobject>
		</figure>

        <para>
            Before going into details, you may want to try out Vaadin TestBench
            yourself. You just need to create a new Vaadin project either with the Eclipse
            plugin or the Maven archetype. Both create a simple application stub that
            includes TestBench test cases for testing the UI. You also need to install an
            evaluation license. For instructions, jump to <xref
            linkend="testbench.quickstart"/> and, after trying it out, come back.
        </para>

        <simplesect>
            <title>The Role of Vaadin TestBench</title>

            <para>
                Vaadin TestBench can work as the centerpiece of the software development
                process, for testing the application at all modular levels and in all the
                phases of the development cycle:
            </para>

            <itemizedlist>
                <listitem><para>Automated acceptance tests</para></listitem>
                <listitem><para>Unit tests</para></listitem>
                <listitem><para>End-to-end integration tests</para></listitem>
                <listitem><para>Regression tests</para></listitem>
            </itemizedlist>

            <para>
                Let us look at each of these topics separately.
            </para>

            <para>
                Any methodological software development, agile or not, is preceded by
                specification of requirements, which define what the software should
                actually do. <emphasis>Acceptance tests</emphasis> ensure that the product
                conforms to the requirements. In agile development, their automation
                allows continuous tracking of progress towards iteration goals, as well as
                regressions, especially when. The importance of requirements is emphasized in
                <emphasis>test-driven development</emphasis> (TDD), where tests are
                written before actual code. In <xref linkend="testbench.bdd"/>, we show
                how to use Vaadin TestBench for <emphasis>behavior-driven
                development</emphasis> (BDD), a special form of TDD that concentrates on
                the formal behavioral specification of requirements.
            </para>

            <para>
                <emphasis>Unit testing</emphasis> is applied to the smallest scale of
                software components; in Vaadin applications these are typically individual
                UI components or view classes. For complex composites, such as views, you
                can use the Page Object Pattern described in <xref
                linkend="testbench.maintainable.pageobject"/>. The pattern simplifies and
                modularizes testing by separating low-level details from the more abstract
                UI logic. In addition to serving the purpose of unit tests, it creates an
                abstraction layer for higher-level tests, such as acceptance and
                end-to-end tests.
            </para>

            <para>
                <emphasis>Integration tests</emphasis> ensure that software units work
                together at different levels of modularization. At the broadest level,
                <emphasis>end-to-end tests</emphasis> extend through the entire
                application lifecycle from start to finish, going through many or all user
                stories. The aim is not just to verify the functional requirements for
                user interaction, but also that data integrity is maintained. For example,
                in a messaging application, a user would log in, both send and receive
                messages, and finally log out. Such test workflows could include
                configuration, registration, interaction between users, administrative
                tasks, deletion of user accounts, and so forth.
            </para>

            <para>
                In regression testing, you want to ensure that only intended changes occur
                in its behaviour after modifying the code, without testing the application
                manually every time. There are two basic ways of detecting such
                regressions. Screenshots are the strictest way, but usually checking the
                displayed values in the HTML is better if you are more interested in the
                content and want to allow some flexibility for themeing, for example. You
                may also want to generate many different kinds of inputs to the
                application and check that they produce the desired outputs.
            </para>

            <para>
                You can develop such tests along with your application code, for example
                with JUnit, which is a widely used Java unit testing framework. You can
                run the tests as many times as you want in your workstation or in a
                distributed grid setup.
            </para>

            <figure xml:id="figure.testbench.workflow">
                <title>TestBench Workflow</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/tt-workflow-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="130" smallscale="90%" align="center" fileref="img/testbench/tt-workflow-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>
        </simplesect>

        <simplesect>
            <title>Features</title>

            <para>
                The main features of Vaadin TestBench are:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Control a browser from Java</para>
                </listitem>
                <listitem>
                    <para>Generate component selectors in debug window</para>
                </listitem>
                <listitem>
                    <para>Validate UI state by assertions and screen capture comparison</para>
                </listitem>
                <listitem>
                    <para>Screen capture comparison with difference highlighting</para>
                </listitem>
                <listitem>
                    <para>Distributed test grid for running tests</para>
                </listitem>
                <listitem>
                    <para>Integration with unit testing</para>
                </listitem>
                <listitem>
                    <para>Test with browsers on mobile devices</para>
                </listitem>
            </itemizedlist>

            <para>
                Execution of tests can be distributed over a grid of test nodes, which
                speeds up testing. The grid nodes can run different operating systems and
                have different browsers installed. In a minimal setup, such as for
                developing the tests, you can use Vaadin TestBench on just a single
                computer.
            </para>
        </simplesect>

        <simplesect>
            <title>Based on Selenium</title>

            <para>
                Vaadin TestBench is based on the Selenium web browser automation library,
                especially Selenium WebDriver, which allows you to control browsers
                straight from Java code.
            </para>

            <para>
                Selenium is augmented with Vaadin-specific extensions, such as:
            </para>

            <itemizedlist>
                <listitem>Proper handling of Ajax-based communications of Vaadin</listitem>
                <listitem>A high-level element query API for Vaadin components</listitem>
                <listitem>Performance testing of Vaadin applications</listitem>
                <listitem>Screen capture comparison</listitem>
                <listitem>Finding HTML elements by a Vaadin selector</listitem>
            </itemizedlist>
        </simplesect>

        <simplesect xml:id="testbench.overview.components">
            <title>TestBench Components</title>

            <para>
                The TestBench library includes WebDriver, which provides API to control a
                browser like a user would. This API can be used to build tests, for
                example, with JUnit.  It also includes the grid hub and node servers,
                which you can use to run tests in a grid configuration.
            </para>

            <para>
                Vaadin TestBench Library provides the central control logic for:
            </para>

            <itemizedlist>
                <listitem>
                    <para>
                        Executing tests with the WebDriver
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Additional support for testing Vaadin-based applications
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Comparing screen captures with reference images
                    </para>
                </listitem>
                <listitem>
                    <para>
                        Distributed testing with grid node and hub services
                    </para>
                </listitem>
            </itemizedlist>
        </simplesect>

        <simplesect xml:id="testbench.overview.requirements">
            <title>Requirements</title>

            <para>
                Requirements for developing and running tests are:
            </para>

            <itemizedlist>
                <listitem>
                    <para>Java JDK 1.6 or newer</para>
                </listitem>
                <listitem>
                    <para>Browsers installed on test nodes as supported by Selenium WebDriver</para>
                    <itemizedlist>
                        <listitem>Google Chrome</listitem>
                        <listitem>Internet Explorer</listitem>
                        <listitem>Mozilla Firefox (ESR version recommended)</listitem>
                        <listitem>Opera</listitem>
                        <listitem>Mobile browsers: Android, iPhone</listitem>
                    </itemizedlist>
                </listitem>

                <listitem>
                    <para>
                        A build system, such as Ant or Maven, to automate execution of
                        tests during build process (recommended)
                    </para>
                </listitem>
            </itemizedlist>

            <para>
                Note that running tests on an Extended Support Release (ESR) version of
                Firefox is recommended because of the frequent release cycle of Firefox,
                which often cause tests to fail. Download an ESR release of Firefox from
                <link
                xlink:href="http://www.mozilla.org/en-US/firefox/organizations/all.html">http://www.mozilla.org/en-US/firefox/organizations/all.html</link>.
                Install it alongside your normal Firefox install (do not overwrite).
            </para>

            <para>
                For Mac OS X, note the issue mentioned in <xref
                linkend="testbench.known-issues.firefox-mac"/>.
            </para>
        </simplesect>

        <simplesect>
            <title>Continuous Integration Compatibility</title>
                
            <para>
                Continuous integration means automatic compilation and testing of
                applications frequently, typically at least daily, but ideally every time
                when code changes are committed to the source repository. This practice
                allows catching integration problems early and finding the changes that
                first caused them to occur.
            </para>

            <para>
                You can make unit tests with Vaadin TestBench just like you would do any
                other Java unit tests, so they work seamlessly with continuous integration
                systems. Vaadin TestBench is tested to work with at least TeamCity and
                Hudson/Jenkins build management and continuous integration servers, which
                all have special support for the JUnit unit testing framework.
            </para>
        </simplesect>

        <simplesect>
            <title>Licensing and Trial Period</title>

            <para>
                You can download Vaadin TestBench from Vaadin Directory and try it out for
                a free 30-day trial period, after which you are required to acquire the
                needed licenses. You can purchase licenses from the Directory.  A license
                for Vaadin TestBench is also included in the Vaadin Pro Account
                subscription.
            </para>
        </simplesect>
    </section>

    <section xml:id="testbench.quickstart">
        <title>Quick Start</title>

        <para>
            With the Eclipse plugin, you need to create a new Vaadin 7 project with the
            TestBench test enabled, as described in <xref
            linkend="getting-started.first-project.creation"/>. The test case stub is
            created under <filename>test</filename> source folder, so that it will not be
            deployed with the application. The project and source folders are illustrated
            in <xref linkend="figure.testbench.quickstart.eclipse-project"
            xrefstyle="select:labelnumber"/>.
        </para>

        <figure xml:id="figure.testbench.quickstart.eclipse-project">
            <title>Eclipse Project with a Test Case</title>
            <mediaobject>
                <imageobject>
                    <imagedata scale="70" smallscale="100%" align="center" fileref="img/testbench/eclipse-project-annotated-hi.png"/>
                </imageobject>
            </mediaobject>
        </figure>

        <para>
            You can observe that the UI and the test case are much like in the
            illustration in <xref linkend="figure.testbench.webdriver"/>.
        </para>

        <para>
            Before running tests, you need to install a license key, as described in <xref
            linkend="testbench.installation.license"/>. For trying out TestBench, you can
            obtain an evaluation license key from the <link
            xlink:href="https://vaadin.com/directory#addon/vaadin-testbench">Vaadin
            TestBench download page</link> in Vaadin Directory.
        </para>

        <para>
            To run the test, open the <filename>MyprojectTest.java</filename> file in the
            editor and press <keycombo
            action="press"><keycombo><keycap>Shift</keycap><keycap>Alt</keycap><keycap>X</keycap></keycombo><keycap>T</keycap></keycombo>. The
            browser should open with the application UI and TestBench run the tests. The
            results are displayed in the <guilabel>JUnit</guilabel> view in Eclipse, as
            shown in <xref linkend="figure.testbench.quickstart.eclipse-junit"/>.
        </para>

        <figure xml:id="figure.testbench.quickstart.eclipse-junit">
            <title>JUnit Test Results in Eclipse</title>
            <mediaobject>
                <imageobject>
                    <imagedata scale="70" smallscale="100%" align="center" fileref="img/testbench/screenshots/eclipse-junit.png"/>
                </imageobject>
            </mediaobject>
        </figure>

        <para>
            With Maven, you need to create a new Vaadin project with the
            <literal>vaadin-archetype-application</literal> archetype, as described in
            <xref linkend="getting-started.maven"/>. The license needs to be installed as
            mentioned above. Then, build the project with the
            <literal>integration-test</literal> or a later phase in the build
            lifecycle. For example, from the command-line:
        </para>

        <screen><prompt>$</prompt> <command>mvn</command> <parameter>integration-test</parameter></screen>

        <para>
            This will execute all required lifecycle phases, including compilation and
            packaging the application, launch Jetty web server to host the application,
            and run the TestBench tests. Results are reported on the console. A Maven GUI,
            such as the one in Eclipse, will provide more visual results.
        </para>
    </section>

    <section xml:id="testbench.installation">
        <title>Installing Vaadin TestBench</title>

        <para>
            As with most Vaadin add-ons, you can install Vaadin TestBench as a Maven or
            Ivy dependency in your project, or from an installation package. The
            installation package contains some extra material, such as demo code and
            documentation.
        </para>

        <para>
            The component element classes are Vaadin-specific. At the time of the writing,
            they are packaged with TestBench, but this will probably change in future.
            <!-- TODO Update when needed -->
        </para>

        <para>
            Additionally, you may need to install drivers for the browsers you are using.
        </para>

        <section xml:id="testbench.installation.development">
            <title>Test Development Setup</title>

            <para>
                In a typical test development setup, you develop tests in a Java project
                and run them on the development workstation. You can run the same tests in
                a dedicated test server, such as a continuous integration system.
            </para>

            <para>
                The Maven dependency would be as follows:
            </para>

            <programlisting><?pocket-size 75% ?>&lt;dependency&gt;
    &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
    &lt;artifactId&gt;vaadin-testbench&lt;/artifactId&gt;
    &lt;version&gt;<emphasis role="bold">4.x.x</emphasis>&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;</programlisting>

            <para>
                The Ivy dependency would be as follows:
            </para>

            <programlisting><?pocket-size 75% ?>&lt;dependency org="com.vaadin" name="vaadin-testbench"
   rev="<emphasis role="bold">4.x.x</emphasis>" conf="test-&lt;default"/&gt;</programlisting>

            <para>
                The optional <literal>test-&lt;default</literal> configuration mapping
                requires a <literal>test</literal> configuration in the Ivy module. It is
                useful especially when building and testing the application in an Ant
                script, where you can use the configuration to define libraries for the
                web application and testing separately. When developing tests in Eclipse,
                it is meaningless, and you can use <literal>default-&lt;default</literal>.
            </para>

            <para>
                We generally recommend developing tests in a project or module separate
                from the web application to be tested to avoid library problems. If the
                tests are part of the same project, you may at least want to arrange the
                source code and dependencies so that the test classes, the TestBench
                library, and their dependencies would not be deployed unnecessarily with
                the web application.
            </para>

            <para>
                In a test development setup, you do not need a grid hub or nodes. However,
                if you develop tests for a grid, you can run the tests, the grid hub, and
                one node all in your development workstation. A distributed setup is
                described in the following section.
            </para>

            <para>
                You may find it convenient to develop and execute tests under an IDE such
                as Eclipse. The special support for running JUnit test cases in Eclipse is
                described in <xref linkend="testbench.development.eclipse"/>.
            </para>
        </section>
            
        <section xml:id="testbench.installation.distributed">
            <title>A Distributed Testing Environment</title>

            <para>
                Vaadin TestBench supports distributed execution of tests in a grid. A test
                grid consists of the following categories of hosts:
            </para>

            <itemizedlist>
                <listitem>
                    <para>One or more test servers executing the tests</para>
                </listitem>
                <listitem>
                    <para>A grid hub</para>
                </listitem>
                <listitem>
                    <para>Grid nodes</para>
                </listitem>
            </itemizedlist>

            <para>
                The components of a grid setup are illustrated in <xref
                    linkend="figure.testbench.architecture"/>.
            </para>

            <figure xml:id="figure.testbench.architecture">
                <title>Vaadin TestBench Grid Setup</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/tt-architecture-simple-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="100" smallscale="100%" align="center" fileref="img/testbench/tt-architecture-simple-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                The grid hub is a service that handles communication between the JUnit
                test runner and the nodes. The nodes are services that perform the actual
                execution of test commands in the browser.
            </para>

            <para>
                The hub requires very little resources, so you would typically run it
                either in the test server or on one of the nodes. You can run the tests,
                the hub, and one node all in one host, but in a fully distributed setup,
                you install the Vaadin TestBench components on separate hosts.
            </para>

            <para>
                Controlling browsers over a distributed setup requires using a remote
                WebDriver.  Grid development and use of the hub and nodes is described in
                <xref linkend="testbench.grid"/>.
            </para>
        </section>

        <section xml:id="testbench.installation.contents">
            <title>Installation Package Contents</title>

            <para>
                The installation package contains the following:
            </para>

            <variablelist>
                <varlistentry>
                    <term><filename>documentation</filename></term>
                    <listitem>
                        <para>
                            The documentation folder contains the TestBench library API documentation,
                            a PDF excerpt of this chapter of Book of Vaadin, and the
                            license.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>example</filename></term>
                    <listitem>
                        <para>
                            The example folder provides TestBench examples. An example
                            Maven configuration POM is given, as well as the JUnit test
                            Java source files. For a description of the contents, see
                            <xref linkend="testbench.installation.examples"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>maven</filename></term>
                    <listitem>
                        <para>
                            The Maven folder contains version of the Vaadin TestBench
                            libraries that you can install in your local Maven
                            repository. Please follow the instructions in <xref
                            linkend="testbench.execution.maven"/>.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>vaadin-testbench-standalone-&version.testbench;.jar</filename></term>
                    <listitem>
                        <para>
                            This is the Vaadin TestBench library. It is a standalone
                            library that includes the Selenium WebDriver and many other
                            required libraries. The library includes the sources and the
                            JavaDoc.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </section>

        <section xml:id="testbench.installation.license">
            <title>Installing a License</title>

            <para>
                To install the license key most conveniently, copy and paste it verbatim
                to a <filename>.vaadin.testbench.developer.license</filename> file in your
                home directory or pass it to the JRE in a system property. See <link
                xlink:href="https://vaadin.com/directory/help/installing-cval-license">the
                AGPL license key installation instructions</link> for more details.
            </para>
        </section>

        <section xml:id="testbench.installation.examples">
            <title>Example Contents</title>

            <para>
                The <filename>example/maven</filename> folder provides a number of
                examples for using Vaadin TestBench. The source code for the application
                to be tested, a desktop calculator application, is given in the
                <filename>src/main/java</filename> subfolder.
            </para>

            <para>
                The tests examples given under the <filename>src/test/java</filename>
                subfolder, in the <filename>com/vaadin/testbenchexample</filename> package
                subfolder, are as follows:
            </para>

            <variablelist>
                <varlistentry>
                    <term><filename>SimpleCalculatorITCase.java</filename></term>
                    <listitem>
                        <para>
                            Demonstrates the basic use of WebDriver. Interacts with the
                            buttons in the user interface by clicking them and checks the
                            resulting value. Uses <methodname>By.id()</methodname> to
                            access the elements.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>LoopingCalculatorITCase.java</filename></term>
                    <listitem>
                        <para>
                            Otherwise as the simple example, but shows how to use looping
                            to produce programmatic repetition to create a complex use
                            case.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>ScreenshotITCase.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to compare screenshots, as described in <xref
                            linkend="testbench.screenshot.comparison"/>. Some of the test cases
                            include random input, so they require masked screenshot
                            comparison to mask the random areas out.
                        </para>

                        <para>
                            The example is ignored by default with an
                            <literal>@Ignore</literal> annotation, because the included
                            images were taken with a specific browser on a specific
                            platform, so if you use another environment, they will
                            fail. If you enable the test, you will need to run the tests,
                            copy the error images to the reference screenshot folder, and
                            mask out the areas with the alpha channel. Please see the
                            <filename>example/Screenshot_Comparison_Tests.pdf</filename>
                            for details about how to enable the example and how to create
                            the masked reference images.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>SelectorExamplesITCase.java</filename></term>
                    <listitem>
                        <para>
                            This example shows how to use different selectors:
                        </para>

                        <itemizedlist>
                            <listitem><methodname>By.id()</methodname> - selecting by identifier</listitem>
                            <listitem><methodname>By.xpath()</methodname> - selecting by an XPath expression</listitem>
                        </itemizedlist>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>VerifyExecutionTimeITCase.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to time the execution of a test case and how to
                            report it.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>AdvancedCommandsITCase.java</filename></term>
                    <listitem>
                        <para>
                            Demonstrates how to test tooltips (<xref
                            linkend="testbench.special.tooltip"/>) and context
                            menus. Uses component IDs, XPath expressions, as well as CSS
                            selectors to find the elements to check.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>pageobjectexample/PageObjectExampleITCase.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to create maintanable tests using the <emphasis>Page
                            Object Pattern</emphasis> that separates the low-level page
                            structure from the business logic, as described in <xref
                            linkend="testbench.maintainable"/>. The page
                            object classes that handle low-level interaction with the
                            application views are in the <filename>pageobjects</filename>
                            subpackage.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><filename>bdd/SimpleCalculation.java</filename></term>
                    <listitem>
                        <para>
                            Shows how to develop tests following the
                            <emphasis>behavior-driven development</emphasis> (BDD) model,
                            by using the <link xlink:href="http://jbehave.org">JBehave
                            framework</link>. <filename>SimpleCalculation.java</filename>
                            defines a JUnit-based user story with one scenario, which is
                            defined in <filename>CalculatorSteps.java</filename>. The
                            scenario reuses the page objects defined in the page object
                            example (see above) for low-level application view access and
                            control.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                For information about running the examples with Maven, see <xref
                linkend="testbench.execution.maven"/>.
            </para>
        </section>

        <section xml:id="testbench.installation.browserdrivers">
            <title>Installing Browser Drivers</title>
                
            <para>
                Whether developing tests with the WebDriver in the workstation or running
                tests in a grid, using some browsers requires that a browser driver is
                installed.
            </para>

            <orderedlist>
                <listitem>
                    <para>Download the latest browser driver</para>

                    <itemizedlist>
                        <listitem>
                            <para>
                                Internet Explorer (Windows only) - install <filename>IEDriverServer.exe</filename> from:
                            </para>
                            <para>
                                <link
                                    xlink:href="http://code.google.com/p/selenium/downloads/list">http://code.google.com/p/selenium/downloads/list</link>
                            </para>
                        </listitem>
                        <listitem>
                            <para>
                                Chrome - install ChromeDriver (a part of the Chromium
                                project) for your platform from:
                            </para>
                            <para>
                                <link
                                    xlink:href="http://code.google.com/p/chromedriver/downloads/list">http://code.google.com/p/chromedriver/downloads/list</link>
                            </para>
                        </listitem>
                    </itemizedlist>
                </listitem>

                <listitem>
                    Add the driver executable to PATH <emphasis>or</emphasis> define it as
                    a system property in the application using WebDriver locally, or in
                    distributed use give it as a command-line parameter to the grid node
                    service, as described in <xref linkend="testbench.grid.node"/>.
                </listitem>
            </orderedlist>
        </section>

        <section xml:id="testbench.installation.testnode">
            <title>Test Node Configuration</title>

            <para>
                If you are running the tests in a grid environment, you need to make some
                configuration to the test nodes to get more stable results.
            </para>

            <para>
                Further configuration is provided in command-line parameters when starting
                the node services, as described in <xref linkend="testbench.grid.node"/>.
            </para>

            <section xml:id="testbench.installation.testnode.os-settings">
                <title>Operating system settings</title>

                <para>
                    Make any operating system settings that might interfere with the browser and how
                    it is opened or closed. Typical problems include crash handler dialogs.
                </para>

                <para>
                    On Windows, disable error reporting in case a browser crashes as follows:
                </para>

                <orderedlist>
                    <listitem>
                        <para>
                            Open <menuchoice><guimenu>Control Panel</guimenu><guimenuitem>System</guimenuitem></menuchoice>
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Select the <guilabel>Advanced</guilabel> tab
                        </para>
                    </listitem>
                    <listitem>
                    <para>
                            Select <guilabel>Error reporting</guilabel>
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Check that <guilabel>Disable error reporting</guilabel> is selected
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Check that <guilabel>But notify me when critical errors occur</guilabel> is not selected
                        </para>
                    </listitem>
                </orderedlist>
            </section>

            <section xml:id="testbench.installation.testnode.screenshot-settings">
                <title>Settings for Screenshots</title>

                <para>
                    The screenshot comparison feature requires that the user interface of
                    the browser stays constant. The exact features that interfere with
                    testing depend on the browser and the operating system.
                </para>

                <para>
                    In general:
                </para>

                <itemizedlist>
                    <listitem>
                        <para>
                            Disable blinking cursor
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Use identical operating system themeing on every host
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Turn off any software that may suddenly pop up a new window
                        </para>
                    </listitem>
                    <listitem>
                        <para>
                            Turn off screen saver
                        </para>
                    </listitem>
                </itemizedlist>
                
                <para>
                    If using Windows and Internet Explorer, you should give also the
                    following setting:
                </para>
                
                <itemizedlist>
                    <listitem>
                        <para>
                            Turn on <guilabel>Allow active content to run in files on My
                            Computer</guilabel> under <guilabel>Security
                            settings</guilabel>
                        </para>
                    </listitem>
                </itemizedlist>
            </section>
        </section>
    </section>

    <section xml:id="testbench.preparing">
        <title>Preparing an Application for Testing</title>

        <para>
            TestBench can usually be used for testing Vaadin applications as they are,
            especially if just taking screenshots.
        </para>

        <para>
            Depending on the selector type that you use later to select HTML elements,
            they can be vulnerable to logically irrelevant changes in the HTML DOM or
            component structure. The structure may change because of your layout or UI
            logic, or if a new Vaadin version has significant changes.
        </para>

        <para>
            To make UIs more robust for testing, you can set a unique <emphasis>component
            ID</emphasis> for specific components with
            <methodname>setId()</methodname>. You can then use it in element queries or
            selectors.
        </para>

        <programlisting><?pocket-size 65% ?><![CDATA[public class UIToBeTested extends UI {
    @Override
    protected void init(VaadinRequest request) {
        final VerticalLayout content = new VerticalLayout();
        setContent(content);
        
        // Create a button
        Button button = new Button("Push Me!");
        
        // Optional: give the button a unique ID
        button.setId("main.button");
        
        // Set the tooltip
        button.setDescription("This is a tip");

        // Do something when the button is clicked
        button.addClickListener(new ClickListener() {
            @Override
            public void buttonClick(ClickEvent event) {
                // This label will not have a set ID
                content.addComponent(new Label("Thanks!"));
            }
        });
        content.addComponent(button);
    }
}]]></programlisting>

        <para>
            The application is shown in <xref
            linkend="figure.testbench.preparing.application-to-be-tested"/>, with the
            button already clicked.
        </para>

        <figure xml:id="figure.testbench.preparing.application-to-be-tested">
            <title>A Simple Application To Be Tested</title>
            <mediaobject>
                <imageobject role="html">
                    <imagedata align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
                <imageobject role="fo">
                    <imagedata scale="120" smallscale="100%" align="center" fileref="img/testbench/screenshots/application-to-be-tested.png"/>
                </imageobject>
            </mediaobject>
        </figure>

        <para>
            The button would be rendered as a HTML element: <literal>&lt;div
            id="main.button" ...&gt;...&lt;/div&gt;</literal>. The DOM element would then
            be accessible from the HTML page with a WebDriver call such as:
            <literal>driver.findElement(By.id="main.button")</literal>. For the label,
            which does not have an ID, the path would be from the page root.
        </para>

        <para>
            As a similar method, you can add a unique CSS class name for a component to
            enable using the CSS selector to select it. You can use the CSS class names
            and IDs also in XPath selectors.
        </para>

        <!-- TODO: A description of different selectors would be needed (XPath, CSS, ...) -->
    </section>

    <section xml:id="testbench.development">
        <title>Developing JUnit Tests</title>

        <para>
            JUnit is a popular unit testing framework for Java development. Most Java
            IDEs, build systems, and continuous integration systems provide support for
            JUnit. However, while we concentrate on the development of JUnit tests in this
            chapter, Vaadin TestBench and the WebDriver are in no way specific to JUnit
            and you can use any test execution framework, or just regular Java
            applications, to develop TestBench tests.
        </para>

        <para>
            You may want to keep your test classes in a separate source tree in your
            application project, or in an altogether separate project, so that you do not
            have to include them in the web application WAR. Having them in the same
            project may be nicer for version control purposes.
        </para>

        <section xml:id="testbench.development.basic">
            <title>Basic Test Case Structure</title>

            <para>
                A JUnit test case is defined with annotations for methods in a test case
                class. With TestBench, the test case class should extend the
                <classname>TestBenchTestcase</classname> class, which provides the
                WebDriver and ElementQuery APIs.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[public class Testcase extends TestBenchTestCase {]]></programlisting>

            <para>
                The available annotations are:
            </para>

            <variablelist>
                <varlistentry>
                    <term><literal>@Before</literal></term>
                    <listitem>
                        <para>
                            The annotated method is executed before each test (annotated
                            with <literal>@Test</literal>). Normally, you create and set
                            the driver here.
                        </para>

                        <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    setDriver(TestBench.createDriver(new FirefoxDriver()));
}]]></programlisting>

                        <para>
                            The driver class should be one of
                            <classname>FirefoxDriver</classname>,
                            <classname>ChromeDriver</classname>,
                            <classname>InternetExplorerDriver</classname>,
                            <classname>SafariDriver</classname>, or
                            <classname>PhantomJSDriver</classname>. Please check
                            <classname>RemoteWebDriver</classname> from API documentation
                            for the current list of implementations. Notice that some of
                            the drivers require installing a browser driver, as described
                            in <xref linkend="testbench.installation.browserdrivers"/>.
                        </para>

                        <para>
                            The driver instance is stored in the <literal>driver</literal>
                            property in the test case. While you can access the property
                            directly by the member variable, you should set it only with
                            the setter.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><literal>@Test</literal></term>
                    <listitem>
                        <para>
                            Annotates a test method. You normally first open the page and
                            then execute commands and make assertions on the content.
                        </para>

                        <programlisting><?pocket-size 70% ?><![CDATA[@Test
public void basic() throws Exception {
    driver.get("http://localhost:8080/tobetested");
    
    // Click the button
    ButtonElement button =
        $(ButtonElement.class).id("content.button");
    button.click();

    // Check that the label text is correct
    LabelElement label = $(LabelElement.class).first();
    assertEquals("Thanks!", label.getText());
}]]></programlisting>

                        <para>
                            Normally, you would define the URL with a variable that is
                            common for all tests, and possibly concatenate it with a URI
                            fragment to get to an application state.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><literal>@After</literal></term>
                    <listitem>
                        <para>
                            After each test is finished, you normally need to quit the
                            driver to close the browser.
                        </para>

                        <programlisting><?pocket-size 75% ?><![CDATA[@After
public void tearDown() throws Exception {
    driver.quit();
}]]></programlisting>

                        <para>
                            However, if you enable grabbing screenshots on failure with
                            the <classname>ScreenshotOnFailureRule</classname>, as
                            described in <xref linkend="testbench.screenshots.failure"/>,
                            the rules are executed after <literal>@After</literal>, but
                            the driver needs to be open when the rule to take the
                            screenshot is executed. Therefore, you should not quit the
                            driver in that case. The rule quits the driver implicitly.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                You can use any other JUnit features. Notice, however, that using
                TestBench requires that the driver has been created and is still open.
            </para>

            <para>
                A complete test case could be as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[import static org.junit.Assert.assertEquals;

import java.util.List;

import org.junit.After;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.openqa.selenium.firefox.FirefoxDriver;

import com.vaadin.testbench.ScreenshotOnFailureRule;
import com.vaadin.testbench.TestBench;
import com.vaadin.testbench.TestBenchTestCase;
import com.vaadin.testbench.elements.ButtonElement;
import com.vaadin.testbench.elements.LabelElement;
import com.vaadin.testbench.elements.VerticalLayoutElement;

public class Testcase extends TestBenchTestCase {
	@Before
	public void setUp() throws Exception {
		setDriver(TestBench.createDriver(new FirefoxDriver()));
	}

    @Test
    public void basic() throws Exception {
        driver.get("http://localhost:8080/tobetested");
        
        // Click the button
        ButtonElement button =
            $(ButtonElement.class).id("content.button");
        button.click();

        // Check that the label text is correct
        LabelElement label = $(LabelElement.class).first();
        assertEquals("Thanks!", label.getText());
    }
    
    @Test
    public void advanced() throws Exception {
        driver.get("http://localhost:8080/tobetested");
        
        // Click all the buttons in the UI
        List<ButtonElement> buttons = $(ButtonElement.class).all();
        for (ButtonElement b: buttons)
            b.click();

        // Check that the label text is correct
        LabelElement label =
            $(VerticalLayoutElement.class).id("content")
            .$(LabelElement.class).first();
        assertEquals("Thanks!", label.getText());
    }

	@After
	public void tearDown() throws Exception {
	    driver.quit();
	}
}]]></programlisting>

        </section>

        <section xml:id="testbench.development.eclipse">
            <title>Running JUnit Tests in Eclipse</title>

            <para>
                The Eclipse IDE integrates JUnit with nice control features. To run
                TestBench JUnit test cases in Eclipse, you need to do the following:
            </para>

            <orderedlist>
                <listitem>
                    <para>
                        Install the TestBench standalone JAR.
                    </para>

                    <orderedlist>
                        <listitem>
                            <para>
                                If using a project created with the Vaadin Plugin for
                                Eclipse, add the TestBench standalone library dependency
                                in <filename>ivy.xml</filename>. It should be as follows:
                            </para>

                            <programlisting><?pocket-size 75% ?><![CDATA[<dependency org="com.vaadin"
            name="vaadin-testbench"
            rev="&version.testbench;"/>]]></programlisting>

                            <para>
                                See <xref linkend="addons.eclipse"/> for more details.
                            </para>
                        </listitem>

                        <listitem>
                            <para>
                                Otherwise, add the TestBench standalone JAR from the
                                installation package to a library folder in the project,
                                such as <filename>lib</filename>. You should not put the
                                library in <filename>WEB-INF/lib</filename> as it is not
                                used by the Vaadin web application. Refresh the project by
                                selecting it and pressing <keycap>F5</keycap>.
                            </para>
                        </listitem>
                    </orderedlist>
                </listitem>

                <listitem>
                    Right-click the project in Project Explorer and select
                    <guilabel>Properties</guilabel>, and open the <guilabel>Java Build
                    Path</guilabel> and the <guilabel>Libraries</guilabel> tab. Click
                    <guibutton>Add JARs</guibutton>, navigate to the library folder,
                    select the library, and click <guibutton>OK</guibutton>.
                </listitem>

                <listitem>
                    Switch to the <guilabel>Order and Export</guilabel> tab in the project
                    properties. Make sure that the TestBench JAR is above the
                    <filename>gwt-dev.jar</filename> (it may contain an old
                    <filename>httpclient</filename> package), by selecting it and moving
                    it with the <guibutton>Up</guibutton> and <guibutton>Down</guibutton>
                    buttons.
                </listitem>

                <listitem>
                    Click <guibutton>OK</guibutton> to exit the project properties.
                </listitem>

                <listitem>
                    Right-click a test source file and select <menuchoice><guimenu>Run
                    As</guimenu><guimenuitem>JUnit Test</guimenuitem></menuchoice>.
                </listitem>
            </orderedlist>

            <para>
                A JUnit view should appear, and it should open the Firefox browser, launch
                the application, run the test, and then close the browser window. If all
                goes well, you have a passed test case, which is reported in the JUnit
                view area in Eclipse, as illustrated in <xref
                linkend="figure.testbench.development.eclipse"/>.
            </para>

            <figure xml:id="figure.testbench.development.eclipse">
                <title>Running JUnit Tests in Eclipse</title>
                <mediaobject>
                    <imageobject>
                        <imagedata scale="85" smallscale="100%" align="center" fileref="img/testbench/screenshots/eclipse-junit-run.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                If you are using some other IDE, it might support JUnit tests as well. If
                not, you can run the tests using Ant or Maven.
            </para>
        </section>
    </section>


    <section xml:id="testbench.testcase">
        <title>Creating a Test Case</title>

        <!-- TODO This is redundant with the next section -->
        <section xml:id="testbench.testcase.setup">
            <title>Test Setup</title>

            <para>
                Test configuration is done in a method annotated with
                <literal>@Before</literal>. The method is executed before each test
                case.
            </para>

            <para>
                The basic configuration tasks are:
            </para>

            <itemizedlist>
                <listitem>Set TestBench parameters</listitem>
                <listitem>Create the web driver</listitem>
                <listitem>Do any other initialization</listitem>
            </itemizedlist>

            <section xml:id="testbench.development.setup.parameters">
                <title>TestBench Parameters</title>

                <para>
                    TestBench parameters are defined with static methods in the
                    <classname>com.vaadin.testbench.Parameters</classname> class. The
                    parameters are mainly for screenshots and documented in <xref
                    linkend="testbench.screenshots"/>.
                </para>
            </section>
        </section>

        <section xml:id="testbench.testcase.basic">
            <title>Basic Test Case Structure</title>

            <para>
                A typical test case does the following:
            </para>

            <orderedlist>
                <listitem>Open the URL</listitem>
                <listitem>Navigate to desired state
                    <orderedlist>
                        <listitem>Find a HTML element (<classname>WebElement</classname>) for navigation</listitem>
                        <listitem>Use <methodname>click()</methodname> and other commands to interact with the element</listitem>
                        <listitem>Repeat with different elements until desired state is reached</listitem>
                    </orderedlist>
                </listitem>
                <listitem>Find a HTML element (<classname>WebElement</classname>) to check</listitem>
                <listitem>Get and assert the value of the HTML element</listitem>
                <listitem>Get a screenshot</listitem>
            </orderedlist>

            <para>
                The <classname>WebDriver</classname> allows finding HTML elements in a
                page in various ways, for example, with XPath expressions. The access
                methods are defined statically in the <classname>By</classname> class.
            </para>

            <para>
                These tasks are realized in the following test code:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testCase1() throws Exception {
    driver.get(baseUrl + "/mycontext/myui");
    
    // Get the button's element.
    // (Actually the caption element inside the button.)
    // Use the component ID assigned with setId().
    WebElement button = driver.findElement(By.xpath(
        "id('main.button'])/span/span"));
    
    // Get the caption text
    assertEquals("Push Me!", button.getText());
    
    // And click it. It's OK to click the caption element.
    button.click();

    // Get the Label's element by its widget path.
    WebElement label = driver.findElement(By.vaadin(
        "mycontextmyui::"+
        "/VVerticalLayout[0]/Slot[1]/VLabel[0]"));

    // Make the assertion
    assertEquals("Thanks!", label.getText());
}]]></programlisting>

            <para>
                You can also use URI fragments in the URL to open the application at a
                specific state. <phrase condition="web">For information about URI fragments, see <xref
                linkend="advanced.urifu"/>.</phrase>
            </para>

            <para>
                You should use the JUnit assertion commands. They are static methods
                defined in the <package>org.junit.Assert</package> class, which you can
                import (for example) with:
            </para>

            <programlisting><![CDATA[import static org.junit.Assert.assertEquals;]]></programlisting>

            <para>
                Please see the <link
                xlink:href="http://seleniumhq.org/docs/03_webdriver.html#selenium-webdriver-api-commands-and-operations">Selenium
                API documentation</link> for a complete reference of the element search
                methods in the <classname>WebDriver</classname> and
                <classname>By</classname> classes and for the interaction commands in the
                <classname>WebElement</classname> class.
            </para>

            <para>
                TestBench has a collection of its own commands, defined in the
                <interfacename>TestBenchCommands</interfacename> interface. You can get a command
                object that you can use by calling <literal>testBench(driver)</literal> in
                a test case.
            </para>

            <para>
                While you can develop tests simply with test cases as described above, for
                the sake of maintainability it is often best to modularize the test code
                further, such as to separate testing at the levels of business logic and
                the page layout. See <xref linkend="testbench.maintainable"/>
                for information about using page objects for this purpose.
            </para>
        </section>

        <section xml:id="testbench.testcase.webdriver">
            <title>Creating and Closing a Web Driver</title>
            
            <para>
                Vaadin TestBench uses Selenium WebDriver to execute tests in a
                browser. The <classname>WebDriver</classname> instance is created with the
                static <methodname>createDriver()</methodname> method in the
                <classname>TestBench</classname> class. It takes the driver as the
                parameter and returns it after registering it. The test cases must extend
                the <classname>TestBenchTestCase</classname> class, which manages the
                TestBench-specific features. You need to store the driver in the test case
                with <methodname>setDriver()</methodname>.
            </para>

            <para>
                The basic way is to create the driver in a method annotated with the
                JUnit <literal>@Before</literal> annotation and close it in a method
                annotated with <literal>@After</literal>.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    @Before
    public void setUp() throws Exception {
        ...
        setDriver(TestBench.createDriver(new FirefoxDriver()));
    }
    ...
    @After
    public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>

            <para>
                This creates the driver for each test you have in the test class, causing
                a new browser instance to be opened and closed. If you want to keep the
                browser open between the tests, you can use <literal>@BeforeClass</literal>
                and <literal>@AfterClass</literal> methods to create and quit the
                driver. In that case, the methods as well as the driver instance have to
                be static.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[public class AdvancedTest extends TestBenchTestCase {
    static private WebDriver driver;

    @BeforeClass
    static public void createDriver() throws Exception {
        driver = TestBench.createDriver(new FirefoxDriver());
    }
    ...
    @AfterClass
    static public void tearDown() throws Exception {
        driver.quit();
    }
}]]></programlisting>

            <section xml:id="testbench.development.webdriver.browsers">
                <title>Browser Drivers</title>

                <para>
                    Please see the API documentation of the
                    <interfacename>WebDriver</interfacename> interface for a complete list
                    of supported drivers, that is, classes implementing the interface.
                </para>

                <para>
                    Both the Internet Explorer and Chrome require a special driver, as was
                    noted in <xref linkend="testbench.installation.browserdrivers"/>. The
                    driver executable must be included in the operating system
                    <literal>PATH</literal>, be given with a driver-specific system
                    Java property:
                </para>

                <itemizedlist>
                    <listitem>Chrome: <parameter>webdriver.chrome.driver</parameter></listitem>
                    <listitem>IE: <parameter>webdriver.ie.driver</parameter></listitem>
                </itemizedlist>

                <para>
                    You can set the property in Java with
                    <methodname>System.setProperty(prop, key))</methodname> or pass it as
                    a command-line parameter to the Java executable with
                    <parameter>-Dwebdriver.chrome.driver=/path/to/driver</parameter>.
                </para>

                <para>
                    If you use an ESR version of Firefox, which is recommended for test
                    stability, you need to the binary when creating the driver as follows:
                </para>

                <programlisting><?pocket-size 65% ?><![CDATA[FirefoxBinary binary =
    new FirefoxBinary(new File("/path/to/firefox_ESR_10"));
driver = TestBench.createDriver(
    new FirefoxDriver(binary, new FirefoxProfile()));]]></programlisting>
            </section>
        </section>
    </section>

    <section xml:id="testbench.elementquery">
        <title>Querying Elements</title>

        <para>
            The high-level ElementQuery API allows querying Vaadin components in the
            browser according to their component class type, hierarchy, caption, and other
            properties. Once one or more components are found, they can be interacted
            upon. The query API forms an domain-specific language (DSL), embedded in the
            <classname>TestBenchTestcase</classname> class.
        </para>

        <para>
            The basic idea of element queries match elements and return queries, which can
            again be queried upon, until terminated by a terminal query that returns one
            or more elements.
        </para>

        <para>
            Consider the following query:
        </para>

        <programlisting><?pocket-size 75% ?><![CDATA[List<ButtonElement> buttons = $(ButtonElement.class).all();]]></programlisting>

        <para>
            The query returns a list of HTML elements of all the
            <classname>Button</classname> components in the UI. Every Vaadin component has
            its corresponding element class, which has methods to interact with the
            particular component type. We could control the buttons found by the query,
            for example, by clicking them as follows:
        </para>

        <!-- TODO ... -->
        <programlisting><?pocket-size 75% ?><![CDATA[for (ButtonElement b: buttons)
    b.click();]]></programlisting>

        <para>
            In the following sub-sections, we look into the details of element queries.
        </para>

        <section xml:id="testbench.elementquery.debugwindow">
            <title>Generating Queries with Debug Window</title>

            <para>
                You can use the debug window to easily generate the element query code to
                select a particular element in the UI. This should be especially useful
                when starting to use TestBench, to get the idea what the queries should be
                like.
            </para>

            <para>
                First, enable the debug window with the <literal>&amp;debug</literal>
                parameter for the application, as described in more detail in <xref
                linkend="advanced.debug"/>. You can interact with the UI in any way you
                like before generating the query code, but we recommend that you proceed
                by following the sequence in which the user would use the UI in each use
                case, making the queries at each step.
            </para>

            <para>
                Switch to the TestBench tab in the debug window, and enable the pick mode
                by clicking the small button. Now, when you hover the mouse pointer on
                elements, it highlights them, and when you click one, it generates the
                TestBench element query to find the element. Use of the debug window is
                illustrated in <xref
                linkend="figure.testbench.elementquery.debugwindow"/>.
            </para>

            <figure xml:id="figure.testbench.elementquery.debugwindow">
                <title>Using Debug Window to Generate Element Queries</title>
                <mediaobject>
                    <imageobject role="html">
                        <imagedata align="center" fileref="img/testbench/debugwindow-select-annotated-lo.png"/>
                    </imageobject>
                    <imageobject role="fo">
                        <imagedata scale="70" smallscale="100%" align="center" fileref="img/testbench/debugwindow-select-annotated-hi.png"/>
                    </imageobject>
                </mediaobject>
            </figure>

            <para>
                You can select and copy and paste the code from the debug window to your
                editor. To exit the pick mode, click the pick button again.
            </para>

            <para>
                The debug window feature is available in Vaadin 7.2 and later.
            </para>
        </section>

        <section xml:id="testbench.elementquery.create">
            <title>Querying Elements by Component Type (<methodname>$</methodname>)</title>

            <para>
                The <methodname>$</methodname> method creates an
                <classname>ElementQuery</classname> that looks for the given element
                class. The method is available both in
                <classname>TestBenchTestcase</classname> and
                <classname>ElementQuery</classname>, which defines the context. The search
                is done recursively in the context.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[// Find the first OK button in the UI
ButtonElement button = $(ButtonElement.class)
    .caption("OK").first();

// A nested query where the context of the latter 
// component type query is the matching elements
// - matches the first Label inside the "content" layout.
LabelElement label = $(VerticalLayoutElement.class)
    .id("content").$(LabelElement.class).first();]]></programlisting>

        </section>

        <section xml:id="testbench.elementquery.nonrecursive">
            <title>Non-Recursive Component Queries (<methodname>$$</methodname>)</title>

            <para>
                The <methodname>$$</methodname> method creates a non-recursive
                <classname>ElementQuery</classname>. It is a shorthand for first creating
                a recursive query with <methodname>$</methodname> and then calling
                <methodname>recursive(false)</methodname> for the query.
            </para>
        </section>

        <section xml:id="testbench.elementquery.testbenchelement">
            <title>Element Classes</title>

            <indexterm zone="testbench.elementquery.testbenchelement">
                <primary><classname>TestBenchElement</classname></primary>
            </indexterm>

            <para>
                Each Vaadin component has a corresponding element class in TestBench,
                which contains methods for interacting with the particular component. The
                element classes extend <classname>TestBenchElement</classname>. It
                implements Selenium <interfacename>WebElement</interfacename>, so the
                Selenium element API can be used directly. The element classes are
                distributed in a Vaadin library rather than with TestBench, as they must
                correspond with the Vaadin version used in the application.
            </para>

            <para>
                In addition to components, other Vaadin UI elements such as notifications
                (see <xref linkend="testbench.special.notifications"/>) can have their
                corresponding element class. Add-on libraries may also define their custom
                element classes.
            </para>

            <para>
                <classname>TestBenchElement</classname> is a TestBench command executor,
                so you can always use an element to create query in the sub-tree of the
                element. For example, in the following we first find a layout element by
                its ID and then do a sub-query to find the first label in it:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[VerticalLayoutElement layout =
    $(VerticalLayoutElement.class).id("content");
LabelElement label = layout.$(LabelElement.class).first();]]></programlisting>

        </section>

        <section xml:id="testbench.elementquery.elementquery">
            <title><classname>ElementQuery</classname> Objects</title>

            <para>
                You can use an <classname>ElementQuery</classname> object to either make
                sub-queries to refine the query, or use a query terminator to finalize the
                query and get one or more matching elements.
            </para>
        </section>

        <section xml:id="testbench.elementquery.terminators">
            <title>Query Terminators</title>

            <para>
                A query is finalized by a sub-query that returns an element or a
                collection of elements.
            </para>

            <variablelist>
                <varlistentry>
                    <term><methodname>first()</methodname></term>
                    <listitem>
                        <para>
                            Returns the first found element.
                        </para>
                    </listitem>
                </varlistentry>            
                <varlistentry>
                    <term><methodname>get()</methodname></term>
                    <listitem>
                        <para>
                            Returns the element by index in the collection of matching
                            elements.
                        </para>
                    </listitem>
                </varlistentry>            
                <varlistentry>
                    <term><methodname>all()</methodname></term>
                    <listitem>
                        <para>
                            Returns a <interfacename>List</interfacename> of elements of
                            the query type.
                        </para>
                    </listitem>
                </varlistentry>            
                <varlistentry>
                    <term><methodname>id()</methodname></term>
                    <listitem>
                        <para>
                            Returns the unique element having the given ID. Element IDs
                            must always be unique in the web page. It is therefore
                            meaningless to make a complex query to match the ID, just
                            matching the element class is enough.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <section xml:id="testbench.elementquery.elements">
                <title>Web Elements</title>

                <para>
                    A query returns one or more elements extending Selenium
                    <classname>WebElement</classname>. The particular element-specific
                    class offers methods to manipulate the associated Vaadin component,
                    while you can also use the lower-level general-purpose methods defined
                    in <classname>WebElement</classname>.
                </para>
            </section>
        </section>
    </section>

    <section xml:id="testbench.selectors">
        <title>Element Selectors</title>

        <para>
            In addition to the high-level ElementQuery API described in the previous
            section, Vaadin TestBench includes the lower-level Selenium WebDriver API,
            with Vaadin extensions. You can find elements also by a plain XPath
            expression, an element ID, CSS style class, and so on. You can use such
            selectors together with the element queries. Like the ElementQuery API, it can
            be considered a domain-specific language (DSL) that is embedded in the
            <classname>TestBenchTestcase</classname> class.
        </para>

        <para>
            The available selectors are defined as static methods in the
            <classname>com.vaadin.testbench.By</classname> class. They create and return a
            <classname>By</classname> instance, which you can use for the
            <methodname>findElement()</methodname> method in
            <classname>WebDriver</classname>.
        </para>

        <!-- TODO Something here. -->

        <para>
            The ID, CSS class, and Vaadin selectors are described below. For others, we
            refer to the <link
            xlink:href="http://seleniumhq.org/docs/03_webdriver.html">Selenium WebDriver
            API documentation</link>.
        </para>

        <para>
            Some selectors are not applicable to all elements, for example if an element
            does not have an ID or it is outside the Vaadin application. In such case,
            another selector is used according to a preference order. You can change the
            order of the preferred selectors by selecting
            <menuchoice><guimenu>Options</guimenu><guisubmenu>Options</guisubmenu><guimenuitem>Locator
            Builders</guimenuitem></menuchoice> and dragging the selectors (or locators)
            to a preferred order. Normally, the Vaadin selector should be at top of the
            list.
        </para>

        <section xml:id="testbench.selectors.robustness">
            <title>Selector Robustness</title>

            <para>
                Before we proceed, it is important to note that selectors have differences
                in their robustness. Robustness is important for avoiding failed tests
                when there are irrelevant changes in the HTML DOM tree.
            </para>

            <para>
                The ElementQuery API and the Vaadin selector
                (<methodname>By.vaadin()</methodname>) use the logical widget hierarchy to
                find the HTML element to test, instead of the exact DOM structure. This
                makes them rather robust, though still vulnerable to irrelevant changes in
                the exact component hierarchy.
            </para>

            <para>
                The XPath selector can be highly vulnerable to changes in the DOM path if
                the path is given exactly from the body element of the page. It is,
                however, very flexible, and can be used in robust ways, for example, by
                selecting by HTML element and a CSS class name or an attribute value.
            </para>

            <para>
                You can likewise use a CSS selector to select specific components by CSS
                class in a robust way.
            </para>
        </section>

        <section xml:id="testbench.selectors.id">
            <title>Finding by ID</title>

            <para>
                Selecting elements by their HTML element <literal>id</literal>
                attribute is usually the easiest way to select elements. It requires
                that you use component IDs, as described in <xref
                    linkend="testbench.preparing"/>. The ID is used as is for the
                <literal>id</literal> attribute of the top element of the
                component. Selecting is done by the <methodname>By.id()</methodname>
                selector.
            </para>

            <para>
                For example, in the <filename>SimpleCalculatorITCase.java</filename>
                example, we use the component ID as follows to click on the calculator
                buttons:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[@Test
public void testOnePlusTwo() throws Exception {
    openCalculator();

    // Click the buttons in the user interface
    getDriver().findElement(By.id("button_1")).click();
    getDriver().findElement(By.id("button_+")).click();
    getDriver().findElement(By.id("button_2")).click();
    getDriver().findElement(By.id("button_=")).click();

    // Get the result label value
    assertEquals("3.0", getDriver().findElement(
            By.id("display")).getText());
}]]></programlisting>

            <para>
                The ID selectors are used extensively in the TestBench examples.
            </para>
        </section>

        <section xml:id="testbench.selectors.vaadin">
            <title>Finding by Vaadin Selector</title>

            <para>
                In addition to the Selenium selectors, Vaadin TestBench provides a
                <emphasis>Vaadin selector</emphasis>, which allows pointing to a Vaadin
                component by its layout widget path. The element query API is in fact an
                API to create Vaadin selectors.
            </para>

            <para>
                You can create a Vaadin selector with the
                <methodname>By.vaadin()</methodname> method. You need to use the
                Vaadin <classname>By</classname>, defined in the
                <package>com.vaadin.testbench</package> package, which extends the
                Selenium <classname>By</classname>.
            </para>

            <para>
                A Vaadin selector begins with a UI identifier. It is the
                URL path of the UI, but without any slashes or other special
                characters. For example, <literal>/book-examples/tobetested</literal>
                would be <literal>bookexamplestobetested</literal>. After the
                identifier, comes two colons "<literal>::</literal>", followed by a
                slash-delimited component path to the component to be selected. The
                elements in the component path are client-side classes of the Vaadin
                user interfacer components. For example, the server-side
                <classname>VerticalLayout</classname> component has
                <classname>VVerticalLayout</classname> client-side counterpart. All
                path elements except the leaves are component containers, usually
                layouts. The exact contained component is identified by its index in
                brackets.
            </para>

            <para>
                A reference to a component ID is given with a <literal>PID_S</literal>
                suffix to the ID.
            </para>

            <para>
                For example, if the ID is <literal>main.button</literal>, as it was
                set in the application example earlier, you could find and test it as
                follows:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[// Get the button's element.
// Use the ID set with setId().
WebElement button = driver.findElement(By.vaadin(
    "bookexamplestobetested::PID_Smain.button"));

// Get the caption text
assertEquals("Push Me!", button.getText());

// And click it
button.click();

// Get the Label's element by full path
WebElement label = driver.findElement(By.vaadin(
    "bookexamplestobetested::/VVerticalLayout[0]/"+
    "ChildComponentContainer[1]/VLabel[0]"));

// Make the assertion
assertEquals("Thanks!", label.getText());]]></programlisting>

        </section>

        <section xml:id="testbench.selectors.css">
            <title>Finding by CSS Class</title>

            <para>
                An element with a particular CSS style class name can be selected with the
                <methodname>By.className()</methodname> method. CSS selectors are useful
                for elements which have no ID, nor can be found easily from the component
                hierarchy, but do have a particular unique CSS style. Tooltips are one
                example, as they are floating <literal>div</literal> elements under the
                root element of the application. Their <literal>v-tooltip</literal> style
                makes it possible to select them as follows:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[// Verify that the tooltip contains the expected text
String tooltipText = driver.findElement(
    By.className("v-tooltip")).getText();]]></programlisting>

            <para>
                For a complete example, see the
                <filename>AdvancedCommandsITCase.java</filename> file in the examples.
            </para>
        </section>
    </section>

    <section xml:id="testbench.special">
        <title>Special Test Features</title>

        <para>
            In the following, we go through a number of TestBench features for handling
            special cases, such as tooltips, scrolling, notifications, context menus, and
            profiling responsiveness. Finally, we look into the Page Object pattern.
        </para>

        <section xml:id="testbench.special.waitforvaadin">
            <title>Waiting for Vaadin</title>

            <para>
                Selenium, on which Vaadin TestBench is based, is originally intended for
                regular web applications that load a page that is immediately rendered by
                the browser. In such applications, you can test the page elements
                immediately after the page is loaded. In Vaadin and other AJAX
                applications, rendering is done by JavaScript code asynchronously, so you
                need to wait until the server has given its response to an AJAX request
                and the JavaScript code finishes rendering the UI. Selenium supports AJAX
                applications by having special wait methods to poll the UI until the
                rendering is finished. In pure Selenium, you need to use the wait methods
                explicitly, and know what to use and when. Vaadin TestBench works together
                with the client-side engine of Vaadin framework to immediately detect when
                the rendering is finished. Waiting is implicit, so you do not normally
                need to insert any wait commands yourself.
            </para>

            <para>
                Waiting is automatically enabled, but it may be necessary to disable it in
                some cases. You can do that by calling
                <methodname>disableWaitForVaadin()</methodname> in the
                <interfacename>TestBenchCommands</interfacename> interface. You can call
                it in a test case as follows:
            </para>

            <programlisting><![CDATA[testBench(driver).disableWaitForVaadin();]]></programlisting>

            <para>
                When disabled, you can wait for the rendering to finish by calling
                <methodname>waitForVaadin()</methodname> explicitly.
            </para>

            <programlisting><![CDATA[testBench(driver).waitForVaadin();]]></programlisting>

            <para>
                You can re-enable the waiting with
                <methodname>enableWaitForVaadin()</methodname> in the same interface.
            </para>
        </section>

        <section xml:id="testbench.special.tooltip">
            <title>Testing Tooltips</title>

            <para>
                Component tooltips show when you hover the mouse over a component. Showing
                them require special command. Handling them is also special, as the
                tooltips are floating overlay element, which are not part of the normal
                component hierarchy.
            </para>

            <para>
                Let us assume that you have set the tooltip as follows:
            </para>

            <programlisting><![CDATA[// Create a button with a component ID
Button button = new Button("Push Me!");
button.setId("main.button");

// Set the tooltip        
button.setDescription("This is a tip");]]></programlisting>

            <para>
                The tooltip of a component is displayed with the
                <methodname>showTooltip()</methodname> method in the
                <classname>TestBenchElementCommands</classname> interface. You should wait
                a little to make sure it comes up. The floating tooltip element is not
                under the element of the component, but you can find it by
                <literal>//div[@class='v-tooltip']</literal> XPath expression.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testTooltip() throws Exception {
    driver.get(appUrl);
    
    ButtonElement button =
        $(ButtonElement.class).id("main.button");

    button.showTooltip();

    WebElement ttip = findElement(By.className("v-tooltip"));
    assertEquals(ttip.getText(), "This is a tip");
}]]></programlisting>

        </section>

        <section xml:id="testbench.special.scrolling">
            <title>Scrolling</title>

            <indexterm zone="testbench.special.scrolling">
                <primary>scrolling</primary>
            </indexterm>

            <para>
                Some Vaadin components, such as <classname>Table</classname> and
                <classname>Panel</classname> have a scrollbar. To get hold of the
                scrollbar, you must first find the component element. Then, you need to
                get hold of the <interfacename>TestBenchElementCommands</interfacename>
                interface from the <classname>WebElement</classname> with
                <methodname>testBenchElement(WebElement)</methodname>. The
                <methodname>scroll()</methodname> method in the interface scrolls a
                vertical scrollbar down the number of pixels given as the parameter. The
                <methodname>scrollLeft()</methodname> scrolls a horizontal scrollbar by
                the given number of pixels.
            </para>
        </section>

        <section xml:id="testbench.special.notifications">
            <title>Testing Notifications</title>

            <indexterm zone="testbench.special.notifications">
                <primary><classname>Notification</classname></primary>
                <secondary>testing</secondary>
            </indexterm>

            <para>
                You can find notification elements by the
                <classname>NotificationElement</classname> class in the element query API.
            </para>

            <para>
                Let us assume that you pop the notifcation up as follows:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[Button button = new Button("Click Me!");
button.addClickListener(new Button.ClickListener() {
    public void buttonClick(ClickEvent event) {
        Notification.show("Thank You!");
    }
});]]></programlisting>

            <para>
                You could then check for the notification as follows:
            </para>

            <programlisting><?pocket-size 70% ?><![CDATA[// Click the button to open the notification
ButtonElement button =
    $(ButtonElement.class).caption("Click Me!").first();
button.click();

// Verify the notification
NotificationElement notification =
        $(NotificationElement.class).first();
assertEquals("Thank You!", notification.getText());
notification.closeNotification();]]></programlisting>

            <para>
                You need to close the notification box with
                <methodname>closeNotification()</methodname> to move forward.
            </para>
        </section>

        <section xml:id="testbench.special.contextmenu">
            <title>Testing Context Menus</title>

            <indexterm zone="testbench.special.contextmenu">
                <primary>context menus</primary>
            </indexterm>

            <para>
                Opening context menus require special handling. You need to create a
                Selenium <classname>Actions</classname> object to perform a context click
                on a <classname>WebElement</classname>.
            </para>

            <para>
                In the following example, we open a context menu in a
                <classname>Table</classname> component, find an item by its caption text,
                and click it.
            </para>

            <programlisting><?pocket-size 70% ?><![CDATA[// Select the table body element
WebElement e = getDriver().findElement(
        By.className("v-table-body"));

// Perform context click action to open the context menu
new Actions(getDriver()).moveToElement(e)
        .contextClick(e).perform();

// Select "Add Comment" from the opened menu
getDriver().findElement(
        By.xpath("//*[text() = 'Add Comment']")).click();]]></programlisting>

            <para>
                The complete example is given in the
                <filename>AdvancedCommandsITCase.java</filename> example source file.
            </para>
        </section>

        <section xml:id="testbench.special.timing">
            <title>Profiling Test Execution Time</title>

            <para>
                It is not just that it works, but also how long it takes. Profiling test
                execution times consistently is not trivial, as a test environment can
                have different kinds of latency and interference. For example in a
                distributed setup, timings taken on the test server would include the
                latencies between the test server, the grid hub, a grid node running the
                browser, and the web server running the application. In such a setup, you
                could also expect interference between multiple test nodes, which all
                might make requests to a shared application server and possibly also share
                virtual machine resources.
            </para>

            <para>
                Furthermore, in Vaadin applications, there are two sides which need to be
                profiled: the server-side, on which the application logic is executed, and
                the client-side, where it is rendered in the browser. Vaadin TestBench
                includes methods for measuring execution time both on the server-side and
                the client-side.
            </para>

            <para>
                The <interfacename>TestBenchCommands</interfacename> interface offers the
                following methods for profiling test execution time:
            </para>

            <variablelist>
                <varlistentry>
                    <term><methodname>totalTimeSpentServicingRequests()</methodname></term>
                    <listitem>
                        <para>
                            Returns the total time (in milliseconds) spent servicing requests in the
                            application on the server-side. The timer starts when you
                            first navigate to the application and hence start a new
                            session. The time passes only when servicing requests for the
                            particular session.  The timer is shared in the servlet
                            session, so if you have, for example, multiple portlets in the
                            same application (session), their execution times will be
                            included in the same total.

                            <!-- TODO Vaadin 7: windows to roots -->
                        </para>

                        <para>
                            Notice that if you are also interested in the client-side
                            performance for the last request, you must call the
                            <methodname>timeSpentRenderingLastRequest()</methodname>
                            before calling this method. This is due to the fact that this
                            method makes an extra server request, which will cause an
                            empty response to be rendered.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>timeSpentServicingLastRequest()</methodname></term>
                    <listitem>
                        <para>
                            Returns the time (in milliseconds) spent servicing the last
                            request in the application on the server-side. Notice that not
                            all user interaction through the WebDriver cause server
                            requests.
                        </para>

                        <para>
                            As with the total above, if you are also interested in the
                            client-side performance for the last request, you must call
                            the <methodname>timeSpentRenderingLastRequest()</methodname>
                            before calling this method.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>totalTimeSpentRendering()</methodname></term>
                    <listitem>
                        <para>
                            Returns the total time (in milliseconds) spent rendering the
                            user interface of the application on the client-side, that is,
                            in the browser. This time only passes when the browser is
                            rendering after interacting with it through the WebDriver. The
                            timer is shared in the servlet session, so if you have, for
                            example, multiple portlets in the same application (session),
                            their execution times will be included in the same total.
                        </para>
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><methodname>timeSpentRenderingLastRequest()</methodname></term>
                    <listitem>
                        <para>
                            Returns the time (in milliseconds) spent rendering user
                            interface of the application after the last server
                            request. Notice that not all user interaction through the
                            WebDriver cause server requests.
                        </para>

                        <para>
                            If you also call the
                            <methodname>timeSpentServicingLastRequest()</methodname> or
                            <methodname>totalTimeSpentServicingRequests()</methodname>,
                            you should do so before calling this method. The methods cause
                            a server request, which will zero the rendering time measured
                            by this method.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                 Generally, only interaction with fields in the
                 <emphasis>immediate</emphasis> mode cause server requests. This includes
                 button clicks. Some components, such as <classname>Table</classname>,
                 also cause requests otherwise, such as when loading data while
                 scrolling. Some interaction could cause multiple requests, such as when
                images are loaded from the server as the result of user interaction.
            </para>
            
            <para>
                The following example is given in the
                <filename>VerifyExecutionTimeITCase.java</filename> file under the
                TestBench examples.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void verifyServerExecutionTime() throws Exception {
    openCalculator();

    // Get start time on the server-side
    long currentSessionTime = testBench(getDriver())
            .totalTimeSpentServicingRequests();

    // Interact with the application
    calculateOnePlusTwo();

    // Calculate the passed processing time on the serve-side
    long timeSpentByServerForSimpleCalculation = testBench()
        .totalTimeSpentServicingRequests() - currentSessionTime;

    // Report the timing
    System.out.println("Calculating 1+2 took about "
            + timeSpentByServerForSimpleCalculation
            + "ms in servlets service method.");

    // Fail if the processing time was critically long
    if (timeSpentByServerForSimpleCalculation > 30) {
        fail("Simple calculation shouldn't take "
             + timeSpentByServerForSimpleCalculation + "ms!");
    }

    // Do the same with rendering time
    long totalTimeSpentRendering =
            testBench().totalTimeSpentRendering();
    System.out.println("Rendering UI took " +
            totalTimeSpentRendering + "ms");
    if (timeSpentByServerForSimpleCalculation > 400) {
        fail("Rendering UI shouldn't take "
             + timeSpentByServerForSimpleCalculation + "ms!");
    }

    // A regular assertion on the UI state
    assertEquals("3.0", getDriver().findElement(
                        By.id("display")).getText());
}]]></programlisting>

        </section>
    </section>

    <section xml:id="testbench.maintainable">
        <title>Creating Maintainable Tests</title>

        <para>
            The first important rule in developing tests is to keep them readable and
            maintainable. Otherwise, when the test fail, such as after refactoring the
            application code, the developers get impatient in trying to understand them to
            fix them, and easily disable them. Readability and maintainability can be
            improved with the Page Object Pattern described below.
        </para>

        <para>
            The second rule is to run the tests often. It is best to use a continuous
            integration server to run them at least once a day, or preferably on every
            commit.
        </para>

        <section xml:id="testbench.maintainable.pageobject">
            <title>The Page Object Pattern</title>

            <para>
                The Page Object Pattern aims to simplify and modularize testing
                application views. The pattern follows the design principle of <link
                xlink:href="http://en.wikipedia.org/wiki/Separation_of_concerns">separation
                of concerns</link>, to handle different concerns in separate modules,
                while hiding information irrelevant to other tests by encapsulation.
            </para>

            <para>
                A <emphasis>page object</emphasis> has methods to interact with a view or
                a sub-view, and to retrieve values in the view. You also need a method to
                open the page and navigate to the proper view.
            </para>

            <para>
                For example:
            </para>

            <programlisting><?pocket-size 70% ?><![CDATA[public class CalculatorPageObject
       extends TestBenchTestCase {
    @FindBy(id = "button_=")
    private WebElement equals;
    ...

    /**
     * Opens the URL where the calculator resides.
     */
    public void open() {
        getDriver().get(
            "http://localhost:8080/?restartApplication");
    }

    /**
     * Pushes buttons on the calculator
     *
     * @param buttons the buttons to push: "123+2", etc.
     * @return The same instance for method chaining.
     */
    public CalculatorPageObject enter(String buttons) {
        for (char numberChar : buttons.toCharArray()) {
            pushButton(numberChar);
        }
        return this;
    }

    /**
     * Pushes the specified button.
     *
     * @param button The character of the button to push.
     */
    private void pushButton(char button) {
        getDriver().findElement(
            By.id("button_" + button)).click();
    }

    /**
     * Pushes the equals button and returns the contents
     * of the calculator "display".
     *
     * @return The string (number) shown in the "display"
     */
    public String getResult() {
        equals.click();
        return display.getText();
    }

    ...
}]]></programlisting>

            <para>
                If you have <classname>WebElement</classname> members annotated with
                <classname>@FindBy</classname>, they can be automatically filled with the
                HTML element matching the given component ID, as if done with
                <literal>driver.findElement(By.id(fieldname))</literal>. To do so, you
                need to create the page object with <classname>PageFactory</classname> as
                is done in the following test setup:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[
public class PageObjectExampleITCase {
    private CalculatorPageObject calculator;

    @Before
    public void setUp() throws Exception {
        driver = TestBench.createDriver(new FirefoxDriver());

        // Use PageFactory to automatically initialize fields
        calculator = PageFactory.initElements(driver,
                         CalculatorPageObject.class);
    }
    ...]]></programlisting>

            <para>
                Test cases can use these methods at business logic level, without knowing
                about the exact structure of the views.
            </para>

            <para>
                For example:
            </para>
            
            <programlisting><?pocket-size 75% ?><![CDATA[@Test
public void testAddCommentRowToLog() throws Exception {
    calculator.open();

    // Just do some math first
    calculator.enter("1+2");

    // Verify the result of the calculation
    assertEquals("3.0", calculator.getResult());

    ...
}]]></programlisting>

            <para>
                You can find the complete example of the Page Object Pattern in the
                <filename>example/src/test/java/com/vaadin/testbenchexample/pageobjectexample/</filename>
                folder in the TestBench installation package. The
                <filename>PageObjectExampleITCase.java</filename> runs tests on the Calc
                UI (also included in the example sources), using the page objects to
                interact with the different parts of the UI and to check the results.
            </para>

            <para>
                The page objects included in the <filename>pageobjects</filename>
                subfolder are as follows:
            </para>

            <itemizedlist>
                <listitem><para>The <classname>CalculatorPageObject</classname> (as
                outlined in the example code above) has methods to click the buttons in
                the calculator and the retrieve the result shown in the
                "display".</para></listitem>

                <listitem><para>The <classname>LogPageObject</classname> can retrieve the
                content of the log entries in the log table, and right-click them to open
                the comment sub-window.</para></listitem>

                <listitem><para>The <classname>AddComment</classname> can enter a comment
                string in the comment editor sub-window and submit it (click the
                <guilabel>Add</guilabel> button).</para></listitem>
            </itemizedlist>
        </section>
    </section>

    <section xml:id="testbench.screenshots">
        <title>Taking and Comparing Screenshots</title>

        <para>
            You can take and compare screenshots with reference screenshots taken
            earlier. If there are differences, you can fail the test case.
        </para>
        
        <section xml:id="testbench.screenshots.parameters">
            <title>Screenshot Parameters</title>

            <para>
                The screenshot configuration parameters are defined with static methods in
                the <classname>com.vaadin.testbench.Parameters</classname> class.
            </para>

            <variablelist>
                <varlistentry>
                    <term><parameter>screenshotErrorDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where screenshots for failed tests or
                        comparisons are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotReferenceDirectory</parameter> (default: <literal>null</literal>)</term>
                    <listitem>
                        Defines the directory where the reference images for screenshot
                        comparison are stored.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonTolerance</parameter> (default: <literal>0.01</literal>)</term>
                    <listitem>
                        Screen comparison is usually not done with exact pixel values,
                        because rendering in browser often has some tiny
                        inconsistencies. Also image compression may cause small artifacts.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotComparisonCursorDetection</parameter> (default: <literal>false</literal>)</term>
                    <listitem>
                        Some field component get a blinking cursor when they have the
                        focus. The cursor can cause unnecessary failures depending on
                        whether the blink happens to make the cursor visible or invisible
                        when taking a screenshot. This parameter enables cursor detection
                        that tries to minimize these failures.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>maxScreenshotRetries</parameter> (default: 2)</term>
                    <listitem>
                        Sometimes a screenshot comparison may fail because the screen
                        rendering has not yet finished, or there is a blinking cursor that
                        is different from the reference screenshot. For these reasons,
                        Vaadin TestBench retries the screenshot comparison for a number of
                        times defined with this parameter.
                    </listitem>
                </varlistentry>
                <varlistentry>
                    <term><parameter>screenshotRetryDelay</parameter> (default: <literal>500</literal>)</term>
                    <listitem>
                        Delay in milliseconds for making a screenshot retry when a
                        comparison fails.
                    </listitem>
                </varlistentry>
            </variablelist>

            <para>
                For example:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    Parameters.setScreenshotErrorDirectory(
        "screenshots/errors");
    Parameters.setScreenshotReferenceDirectory(
        "screenshots/reference");
    Parameters.setMaxScreenshotRetries(2);
    Parameters.setScreenshotComparisonTolerance(1.0);
    Parameters.setScreenshotRetryDelay(10);
    Parameters.setScreenshotComparisonCursorDetection(true);
    Parameters.setCaptureScreenshotOnFailure(true);
}
]]></programlisting>

        </section>

        <section xml:id="testbench.screenshots.failure">
            <title>Taking Screenshots on Failure</title>

            <!-- TODO: What is wrong with this? -->

            <para>
                Vaadin TestBench can take screenshots automatically when a test fails. To
                enable the feature, you need to include the
                <classname>ScreenshotOnFailureRule</classname> JUnit rule with a member
                variable annotated with <classname>@Rule</classname> in the test case as
                follows:
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[@Rule
public ScreenshotOnFailureRule screenshotOnFailureRule =
    new ScreenshotOnFailureRule(this, true);]]></programlisting>

            <para>
                Notice that you must not call <methodname>quit()</methodname> for the
                driver in the <literal>@After</literal> method, as that would close the
                driver before the rule takes the screenshot.
            </para>

            <para>
                The screenshots are written to the error directory defined with the
                <parameter>screenshotErrorDirectory</parameter> parameter. You can
                configure it in the test case setup as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Before
public void setUp() throws Exception {
    Parameters.setScreenshotErrorDirectory("screenshots/errors");
    ...
}]]></programlisting>
        </section>

        <section xml:id="testbench.screenshot.comparison">
            <title>Taking Screenshots for Comparison</title>

            <para>
                Vaadin TestBench allows taking screenshots of the web browser window with
                the <methodname>compareScreen()</methodname> command in the
                <classname>TestBenchCommands</classname> interface. The method has a
                number of variants.
            </para>

            <para>
                The <methodname>compareScreen(<classname>File</classname>)</methodname>
                takes a <classname>File</classname> object pointing to the reference
                image. In this case, a possible error image is written to the error
                directory with the same file name. You can get a file object to a
                reference image with the static
                <methodname>ImageFileUtil.getReferenceScreenshotFile()</methodname> helper
                method.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[assertTrue("Screenshots differ",
           testBench(driver).compareScreen(
               ImageFileUtil.getReferenceScreenshotFile(
                   "myshot.png")));]]></programlisting>

            <para>
                The <methodname>compareScreen(<classname>String</classname>)</methodname>
                takes a base name of the screenshot. It is appended with browser
                identifier and the file extension.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[assertTrue(testBench(driver).compareScreen("tooltip"));]]></programlisting>

            <para>
                The <methodname>compareScreen(<classname>BufferedImage</classname>,
                <classname>String</classname>)</methodname> allows keeping the reference
                image in memory. An error image is written to a file with a name
                determined from the base name given as the second parameter.
            </para>

            <para>
                Screenshots taken with the <methodname>compareScreen()</methodname> method
                are compared to a reference image stored in the reference image folder. If
                differences are found (or the reference image is missing), the comparison
                method returns <literal>false</literal> and stores the screenshot in the
                error folder. It also generates an HTML file that highlights the differing
                regions.
            </para>

            <section xml:id="testbench.screenshot.comparison.error-images">
                <title>Screenshot Comparison Error Images</title>

                <para>
                    Screenshots with errors are written to the error folder, which is
                    defined with the <parameter>screenshotErrorDirectory</parameter>
                    parameter described in <xref
                    linkend="testbench.screenshots.parameters"/>.
                </para>

                <para>
                    For example, the error caused by a missing reference image could be
                    written to
                    <filename>screenshot/errors/tooltip_firefox_12.0.png</filename>. The
                    image is shown in <xref
                    linkend="figure.testbench.screenshot.comparison.error-images.calc"/>.
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.error-images.calc">
                    <title>A screenshot taken by a test run</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="60" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-calc.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>

                <para>
                    Screenshots cover the visible page area in the browser. The size of
                    the browser is therefore relevant for screenshot comparison. The
                    browser is normally sized with a predefined default size. You can set
                    the size of the browser window in a couple of ways. You can set the
                    size of the browser window with, for example,
                    <literal>driver.manage().window().setSize(new Dimension(1024,
                    768));</literal> in the <literal>@Before</literal> method. The size
                    includes any browser chrome, so the actual screenshot size will be
                    smaller. To set the actual view area, you can use
                    <literal>TestBenchCommands.resizeViewPortTo(1024, 768)</literal>.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.reference-images">
                <title>Reference Images</title>

                <para>
                    Reference images are expected to be found in the reference image
                    folder, as defined with the
                    <parameter>screenshotReferenceDirectory</parameter> parameter described in
                    <xref linkend="testbench.screenshots.parameters"/>.  To create a
                    reference image, just copy a screenshot from the
                    <filename>errors/</filename> directory to the
                    <filename>reference/</filename> directory.
                </para>

                <para>
                    For example:
                </para>

                <screen><prompt>$</prompt> <command>cp</command> <parameter>screenshot/errors/tooltip_firefox_12.0.png</parameter> <parameter>screenshot/reference/</parameter></screen>

                <para>
                    Now, when the proper reference image exists, rerunning the test
                    outputs success:
                </para>

                <screen><prompt>$</prompt> <command>java</command> ...
JUnit version 4.5
.
Time: 18.222

OK (1 test)</screen>

                <para>
                    You can also supply multiple versions of the reference images by
                    appending an underscore and an index to the filenames. For example:
                </para>

                <screen>tooltip_firefox_12.0.png
tooltip_firefox_12.0_1.png
tooltip_firefox_12.0_2.png</screen>

                <para>
                    This can be useful in certain situations when there actually are more
                    than one "correct" reference.
                </para>
            </section>

            <section xml:id="testbench.screenshots.comparison.masked">
                <title>Masking Screenshots</title>

                <para>
                    You can make masked screenshot comparison with reference images that
                    have non-opaque regions. Non-opaque pixels in the reference image,
                    that is, ones with less than 1.0 value in the alpha channel, are
                    ignored in the screenshot comparison.
                </para>

                <para>
                    Please see the <filename>ScreenshotITCase.java</filename> example in
                    the installation package for an example of using masked
                    screenshots. The
                    <filename>example/Screenshot_Comparison_Tests.pdf</filename> document
                    describes how to enable the example and how to create the screenshot
                    masks in an image editor.
                </para>
            </section>

            <section xml:id="testbench.screenshot.comparison.visualization">
                <title>Visualization of Differences in Screenshots with Highlighting</title>

                <para>
                    Vaadin TestBench supports advanced difference visualization between a
                    captured screenshot and the reference image. A difference report is
                    written to a HTML file that has the same name as the failed
                    screenshot, but with <filename>.html</filename> suffix. The reports are
                    written to the same <filename>errors/</filename> folder as the
                    screenshots from the failed tests.
                </para>

                <para>
                    The differences in the images are highlighted with blue
                    rectangles. Moving the mouse pointer over a square shows the
                    difference area as it appears in the reference image. Clicking the
                    image switches the entire view to the reference image and back. Text
                    "<guilabel>Image for this run</guilabel>" is displayed in the top-left
                    corner of the screenshot to distinguish it from the reference image.
                </para>

                <para>
                    <xref
                    linkend="figure.testbench.screenshot.comparison.visualization.highlighting"/>
                    shows a difference report with one difference between the visualized
                    screenshot (bottom) and the reference image (top).
                </para>

                <figure xml:id="figure.testbench.screenshot.comparison.visualization.highlighting">
                    <title>The reference image and a highlighted error image</title>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="100" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-1.png"/>
                        </imageobject>
                    </mediaobject>
                    <mediaobject>
                        <imageobject role="html">
                            <imagedata align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                        <imageobject role="fo">
                            <imagedata scale="100" smallscale="80%" align="center" fileref="img/testbench/screenshots/tt-screenshot-comparison-2.png"/>
                        </imageobject>
                    </mediaobject>
                </figure>
            </section>
        </section>

        <section xml:id="testbench.screenshot.comparison.practices">
            <title>Practices for Handling Screenshots</title>

            <para>
                Access to the screenshot reference image directory should be arranged
                so that a developer who can view the results can copy the valid images
                to the reference directory. One possibility is to store the reference
                images in a version control system and check-out them to the
                <filename>reference/</filename> directory.
            </para>

            <para>
                A build system or a continuous integration system can be configured to
                automatically collect and store the screenshots as build artifacts.
            </para>
        </section>


        <section xml:id="testbench.screenshot.compatibility">
            <title>Known Compatibility Problems</title>

            <variablelist>
                <varlistentry>
                    <term><para>Screenshots when running Internet Explorer 9 in Compatibility Mode</para></term>
                    <listitem>
                        <para>
                            Internet Explorer prior to version 9 adds a two-pixel border
                            around the content area. Version 9 no longer does this and as
                            a result screenshots taken using Internet Explorer 9 running
                            in compatibility mode (IE7/IE8) will include the two pixel
                            border, contrary to what the older versions of Internet
                            Explorer do.
                        </para>
                    </listitem>
                </varlistentry>
            </variablelist>
        </section>            
    </section>

    <section xml:id="testbench.execution">
        <title>Running Tests</title>

        <para>
            During test development, you usually run the tests from your IDE. After that,
            you want to have them run by a build system, possibly under a continuous
            integration system. In the following, we describe how to run tests by Ant and
            Maven.
        </para>

        <section xml:id="testbench.execution.ant">
            <title>Running Tests with Ant</title>

            <para>
                Apache Ant has built-in support for executing JUnit tests. To enable the
                support, you need to have the JUnit library <filename>junit.jar</filename>
                and its Ant integration library <filename>ant-junit.jar</filename> in the
                Ant classpath, as described in the Ant documentation.
            </para>

            <para>
                Once enabled, you can use the <literal>&lt;junit&gt;</literal> task in an
                Ant script. The following example assumes that the source files are
                located under a <filename>src</filename> directory under the current
                directory and compiles them to the <filename>classes</filename>
                directory. The the class path is defined with the
                <literal>classpath</literal> reference ID and should include the TestBench
                JAR and all relevant dependencies.
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[<project default="run-tests">
    <path id="classpath">
        <fileset dir="lib"
                 includes="vaadin-testbench-standalone-*.jar" />
    </path>

    <!-- This target compiles the JUnit tests. -->
    <target name="compile-tests">
        <mkdir dir="classes" />
        <javac srcdir="src" destdir="classes"
               debug="on" encoding="utf-8">
            <classpath>
                <path refid="classpath" />
            </classpath>
        </javac>
    </target>

    <!-- This target calls JUnit -->
    <target name="run-tests" depends="compile-tests">
        <junit fork="yes">
            <classpath>
                <path refid="classpath" />
                <pathelement path="classes" />
            </classpath>

            <formatter type="brief" usefile="false" />
                                
            <batchtest>
                <fileset dir="src">
                    <include name="**/**.java" />
                </fileset>
            </batchtest>
        </junit>
    </target>
</project>]]></programlisting>

            <para>
                You also need to deploy the application to test, and possibly launch a
                dedicated server for it.
            </para>
        </section>

        <section xml:id="testbench.execution.maven">
            <title>Running Tests with Maven</title>

            <para>
                Executing JUnit tests with Vaadin TestBench under Maven requires defining
                it as a dependency in any POM that needs to execute TestBench tests.
            </para>

            <para>
                A complete example of a Maven test setup is given in the
                <filename>example/maven</filename> folder in the installation
                package. Please see the <filename>README</filename> file in the folder for
                further instructions.
            </para>

            <section xml:id="testbench.execution.maven.dependency">
                <title>Defining TestBench as a Dependency</title>

                <para>
                    You need to define the TestBench library as a dependency in the Maven
                    POM of your project as follows:
                </para>

                <programlisting>    &lt;dependency&gt;
      &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
      &lt;artifactId&gt;vaadin-testbench&lt;/artifactId&gt;
      &lt;version&gt;&version.testbench;&lt;/version&gt;
    &lt;/dependency&gt;</programlisting>

                <para>
                    For instructions on how to create a new Vaadin project with Maven,
                    please see <xref linkend="getting-started.maven"/>.
                </para>
            </section>

            <section xml:id="testbench.execution.maven.running">
                <title>Running the Tests</title>

                <para>
                    To compile and run the tests, simply execute the
                    <literal>test</literal> lifecycle phase with Maven as follows:
                </para>

                <screen><prompt>$</prompt> <command>mvn</command> test
...
-----------------------------------------------------
 T E S T S
-----------------------------------------------------
Running TestBenchExample
Tests run: 6, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 36.736 sec &lt;&lt;&lt; FAILURE!

Results :

Failed tests: 
  testDemo(TestBenchExample):
      expected:&lt;[5/17/]12&gt; but was:&lt;[17.6.20]12&gt;

Tests run: 6, Failures: 1, Errors: 0, Skipped: 1
...</screen>

                <para>
                    The example configuration starts Jetty to run the application that is
                    tested.
                </para>

                <para>
                    If you have screenshot tests enabled, as mentioned in <xref
                    linkend="testbench.installation.examples"/>, you will get failures
                    from screenshot comparison. The failed screenshots are written to the
                    <filename>target/testbench/errors</filename> folder. To enable
                    comparing them to "expected" screenshots, you need to copy the
                    screenshots to the
                    <filename>src/test/resources/screenshots/reference/</filename>
                    folder. See <xref linkend="testbench.screenshots"/> for more
                    information regarding screenshots.
                </para>
            </section>
        </section>
    </section>

    <section xml:id="testbench.grid">
        <title>Running Tests in a Distributed Environment</title>

        <para>
            A distributed test environment consists of a grid hub and a number of test
            nodes. The hub listens to calls from test runners and delegates them to the
            grid nodes. Different nodes can run on different operating system platforms
            and have different browsers installed.
        </para>

        <para>
            A basic distributed installation was covered in <xref
            linkend="testbench.installation.distributed"/>.
        </para>

        <section xml:id="testbench.grid.remote">
            <title>Running Tests Remotely</title>

            <para>
                Remote tests are just like locally executed JUnit tests, except instead of
                using a browser driver, you use a <classname>RemoteWebDriver</classname>
                that can connect to the hub. The hub delegates the connection to a grid
                node with the desired capabilities, that is, which browsers are installed
                in a suitable node. The capabilities are described with a
                <classname>DesiredCapabilities</classname> object.
            </para>

            <para>
                For example, in the example tests given in the <filename>example</filename>
                folder, we create and use a remote driver as follows:
            </para>

            <programlisting><?pocket-size 65% ?><![CDATA[@Test
public void testRemoteWebDriver() throws MalformedURLException {
    // Require Firefox in the test node
    DesiredCapabilities capability =
        DesiredCapabilities.firefox();

    // Create a remote web driver that connects to a hub
    // running in the local host
    WebDriver driver = TestBench.createDriver(
        new RemoteWebDriver(new URL(
            "http://localhost:4444/wd/hub"), capability));

    // Then use it to run a test as you would use any web driver
    try {
        driver.navigate().to(
            "http://demo.vaadin.com/sampler#TreeActions");
        WebElement e = driver.findElement(By.xpath(
            "//div[@class='v-tree-node-caption']"+
            "/div[span='Desktops']"));
        new Actions(driver).moveToElement(e).contextClick(e)
            .perform();
    } finally {
        driver.quit();
    }
}
]]></programlisting>

            <para>
                Please see the API documentation of the
                <classname>DesiredCapabilities</classname> class for a complete list of
                supported capabilities.
            </para>

            <para>
                Running the example requires that the hub service and the nodes are
                running. Starting them is described in the subsequent sections. Please
                refer to <link
                xlink:href="http://seleniumhq.org/docs/07_selenium_grid.html">Selenium
                documentation</link> for more detailed information.
            </para>
        </section>

        <section xml:id="testbench.grid.hub">
            <title>Starting the Hub</title>
            
            <para>
                The TestBench grid hub listens to calls from test runners and delegates
                them to the grid nodes. The grid hub service is included in the Vaadin
                TestBench JAR and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar vaadin-testbench-standalone-&version.testbench;.jar \
       -role hub</screen>

            <para>
                You can open the control interface of the hub also with a web
                browser. Using the default port, just open URL
                <uri>http://localhost:4444/</uri>. Once you have started one or more grid
                nodes, as instructed in the next section, the "console" page displays a
                list of the grid nodes with their browser capabilities.
            </para>
        </section>

        <section xml:id="testbench.grid.node-configuration">
            <title>Node Service Configuration</title>

            <para>
                Test nodes can be configured with command-line options, as described
                later, or in a configuration file in JSON format. If no configuration file
                is provided, a default configuration is used.
            </para>

            <para>
                A node configuration file is specified with the
                <parameter>-nodeConfig</parameter> parameter to the node service, for
                example as follows:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar vaadin-testbench-standalone-&version.testbench;.jar
       -role node -nodeConfig <parameter>nodeConfig.json</parameter></screen>

            <para>
                See <xref linkend="testbench.grid.node"/> for further details on starting
                the node service.
            </para>

            <section xml:id="testbench.grid.node-configuration.format">
                <title>Configuration File Format</title>

                <para>
                    The test node configuration file follows the JSON format, which
                    defines nested associative maps. An associative map is defined as a
                    block enclosed in curly braces (<literal>{}</literal>). A mapping is a
                    key-value pair separated with a colon (<literal>:</literal>). A key is
                    a string literal quoted with double quotes
                    (<literal>"key"</literal>). The value can be a string literal, list,
                    or a nested associative map. A list a comma-separated sequence
                    enclosed within square brackets (<literal>[]</literal>).
                </para>

                <para>
                    The top-level associative map should have two associations:
                    <literal>capabilities</literal> (to a list of associative maps) and
                    <literal>configuration</literal> (to a nested associative map).
                </para>

                <programlisting><?pocket-size 75% ?>{
  "capabilities":
    [
      {
        "browserName": "<parameter>firefox</parameter>",
        ...
      },
      ...
    ],
  "configuration":
  {
    "port": 5555,
    ...
  }
}</programlisting>

                <para>
                    A complete example is given later.
                </para>
            </section>

            <section xml:id="testbench.grid.node-configuration.capabilities">
                <title>Browser Capabilities</title>

                <para>
                    The browser capabilities are defined as a list of associative maps as
                    the value of the <literal>capabilities</literal> key. The capabilities
                    can also be given from command-line using the
                    <parameter>-browser</parameter> parameter, as described in <xref
                    linkend="testbench.grid.node"/>.
                </para>

                <para>
                    The keys in the map are the following:
                </para>

                <variablelist>
                    <varlistentry>
                        <term><parameter>platform</parameter></term>
                        <listitem>
                            The operating system platform of the test node:
                            <literal>WINDOWS</literal>, <literal>XP</literal>,
                            <literal>VISTA</literal>, <literal>LINUX</literal>, or
                            <literal>MAC</literal>.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>browserName</parameter></term>
                        <listitem>
                            A browser identifier, any of: <literal>android</literal>,
                            <literal>chrome</literal>, <literal>firefox</literal>,
                            <literal>htmlunit</literal>, <literal>internet
                            explorer</literal>, <literal>iphone</literal>,
                            <literal>opera</literal>, or <literal>phantomjs</literal> (as
                            of TestBench 3.1).
                    </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>maxInstances</parameter></term>
                        <listitem>
                            The maximum number of browser instances of this type open at
                            the same time for parallel testing.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>version</parameter></term>
                        <listitem>
                            The major version number of the browser.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>seleniumProtocol</parameter></term>
                        <listitem>
                            This should be <literal>WebDriver</literal> for WebDriver use.
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term><parameter>firefox_binary</parameter></term>
                        <listitem>
                            Full path and file name of the Firefox executable. This is
                            typically needed if you have Firefox ESR installed in a
                            location that is not in the system path.
                        </listitem>
                    </varlistentry>
                </variablelist>
            </section>

            <section xml:id="testbench.grid.node-configuration.server">
                <title>Server Configuration</title>

                <para>
                    The node service configuration is defined as a nested associative map
                    as the value of the <literal>configuration</literal> key. The
                    configuration parameters can also be given as command-line parameters
                    to the node service, as described in <xref linkend="testbench.grid.node"/>.
                </para>

                <para>
                    See the following example for a typical server configuration.
                </para>
            </section>

            <section xml:id="testbench.grid.node-configuration.example">
                <title>Example Configuration</title>

                <programlisting><?pocket-size 75% ?>{
  "capabilities":
    [
      {
        "browserName": "<parameter>firefox</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>",
        "version": "<parameter>10</parameter>",
        "firefox_binary": "<parameter>/path/to/firefox10</parameter>"
      },
      {
        "browserName": "<parameter>firefox</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "version": "<parameter>16</parameter>",
        "firefox_binary": "<parameter>/path/to/firefox16</parameter>"
      },
      {
        "browserName": "<parameter>chrome</parameter>",
        "maxInstances": <parameter>5</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>"
      },
      {
        "platform": "<parameter>WINDOWS</parameter>",
        "browserName": "<parameter>internet explorer</parameter>",
        "maxInstances": <parameter>1</parameter>,
        "seleniumProtocol": "<parameter>WebDriver</parameter>"
      }
    ],
  "configuration":
  {
    "proxy": "org.openqa.grid.selenium.proxy.DefaultRemoteProxy",
    "maxSession": 5,
    "port": 5555,
    "host": ip,
    "register": true,
    "registerCycle": 5000,
    "hubPort": 4444
  }
}</programlisting>
            </section>
        </section>

        <section xml:id="testbench.grid.node">
            <title>Starting a Grid Node</title>

            <para>
                A TestBench grid node listens to calls from the hub and is capable of
                opening a browser. The grid node service is included in the Vaadin
                TestBench JAR and you can start it with the following command:
            </para>

            <screen><prompt>$</prompt> <command>java</command> -jar \
       vaadin-testbench-standalone-&version.testbench;.jar \
       -role node \
       -hub <parameter>http://localhost:4444/grid/register</parameter></screen>

            <para>
                The node registers itself in the grid hub. You need to give the address of
                the hub either with the <parameter>-hub</parameter> parameter or in the
                node configuration file as described in <xref
                linkend="testbench.grid.node-configuration"/>.
            </para>

            <para>
                You can run one grid node in the same host as the hub, as is done in the
                example above with the localhost address.
            </para>

            <section xml:id="testbench.grid.node.browser-capabilities">
                <title>Browser Capabilities</title>

                <para>
                    The browsers installed in the node can be defined either with a
                    command-line parameter or with a configuration file in JSON format, as
                    described in <xref linkend="testbench.grid.node-configuration"/>.
                </para>

                <para>
                    On command-line, you can issue a <parameter>-browser</parameter> option to
                    define the browser capabilities. It must be followed by a comma-separated
                    list of property-value definitions, such as the following:
                </para>

                <screen>-browser "browserName=firefox,version=10,firefox_binary=/path/to/firefox10" \
-browser "browserName=firefox,version=16,firefox_binary=/path/to/firefox16" \
-browser "browserName=chrome,maxInstances=5" \
-browser "browserName=internet explorer,maxInstances=1,platform=WINDOWS"</screen>

                <para>
                    The configuration properties are described in <xref
                    linkend="testbench.grid.node-configuration"/>.
                </para>
            </section>

            <section xml:id="testbench.grid.node.browserdriver">
                <title>Browser Driver Parameters</title>

                <para>
                    If you use Chrome or Internet Explorer, their remote driver
                    executables must be in the system path (in the <literal>PATH</literal>
                    environment variable) or be given with a command-line parameter to the
                    node service:
                </para>

                <variablelist>
                    <varlistentry>
                        <term>Internet Explorer</term>
                        <listitem>
                            <parameter>-Dwebdriver.ie.driver=C:\path\to\IEDriverServer.exe</parameter>
                        </listitem>
                    </varlistentry>
                    <varlistentry>
                        <term>Google Chrome</term>
                        <listitem>
                            <parameter>-Dwebdriver.chrome.driver=/path/to/ChromeDriver</parameter>
                        </listitem>
                    </varlistentry>
                </variablelist>
            </section>
        </section>

        <section xml:id="testbench.grid.mobile">
            <title>Mobile Testing</title>

            <para>
                Vaadin TestBench includes an iPhone and an Android driver, with which you
                can test on mobile devices. The tests can be run either in a device or in
                an emulator/simulator.
            </para>

            <para>
                The actual testing is just like with any WebDriver, using either the
                <classname>IPhoneDriver</classname> or the
                <classname>AndroidDriver</classname>. The Android driver assumes that the
                hub (<filename>android-server</filename>) is installed in the emulator and
                forwarded to port 8080 in localhost, while the iPhone driver assumes port
                3001. You can also use the <classname>RemoteWebDriver</classname> with
                either the <methodname>iphone()</methodname> or the
                <methodname>android()</methodname> capability, and specify the hub URI
                explicitly.
            </para>

            <para>
                The mobile testing setup is covered in detail in the Selenium
                documentation for both the <link
                xlink:href="http://code.google.com/p/selenium/wiki/IPhoneDriver">IPhoneDriver</link>
                and the <link
                xlink:href="http://code.google.com/p/selenium/wiki/AndroidDriver">AndroidDriver</link>.
             </para>
        </section>
    </section>

    <section xml:id="testbench.headless">
        <title>Headless Testing</title>
        
        <para>
            TestBench (3.1 and later) supports fully-featured headless testing with
            PhantomJS (<link
            xlink:href="http://phantomjs.org">http://phantomjs.org</link>), a headless
            browser based on WebKit. It has fast native support for various web standards:
            JavaScript, DOM handling, CSS selector, JSON, Canvas, and SVG.
        </para>

        <para>
            Headless testing using PhantomJS allows for around 15% faster test execution
            without having to start a graphical web browser, even when performing
            screenshot-based testing! This also makes it possible to run full-scale
            functional tests on the front-end directly on a build server, without the need
            to install any web browsers.
        </para>

        <para>
            It is usually best to use a graphical browser to develop the test cases, as it
            is possible to see interactively what happens while the tests are being
            executed.  Once the tests are working correctly in a graphical browser, you
            can migrate them to run on the PhantomJS headless browser.
        </para>
            
        <section xml:id="testbench.headless.running">
            <title>Basic Setup for Running Headless Tests</title>
            
            <para>
                The only set up required is to install the PhantomJS binary. Follow the
                instructions for your operating system at <link
                xlink:href="http://phantomjs.org/download.html">PhantomJS download
                page</link>, and place the binary in the system path.
            </para>
                
            <para>
                The PhantomJSDriver dependency is already included in Vaadin TestBench.
            </para>

            <section xml:id="testbench.headless.running.createwebdriver">
                <title>Creating a Headless WebDriver Instance</title>
                
                <para>
                    Creating an instance of the <classname>PhantomJSDriver</classname> is just
                    as easy as creating an instance of <classname>FirefoxDriver</classname>.
                </para>
                
                <programlisting><?pocket-size 65% ?><![CDATA[setDriver(TestBench.createDriver(
    new PhantomJSDriver(DesiredCapabilities.phantomjs())));]]></programlisting>

                <para>
                    Some tests may fail because of the small default window size in
                    PhantomJS. Such tests are, for example, tests containing elements that
                    pop up and might go off-screen when the window is small. To make them
                    work better, specify a size for the window:
                </para>

                <programlisting><?pocket-size 75% ?><![CDATA[getDriver().manage().window().setSize(
        new Dimension(1024, 768));]]></programlisting>
        	
                <para>
                    Nothing else is needed to run tests headlessly.
                </para>
            </section>
        </section>

        <section xml:id="testbench.headless.grid">
            <title>Running Headless Tests in a Distributed Environment</title>
            
            <para>
                Running PhantomJS in a distributed grid is equally easy. First, install
                PhantomJS in the nodes by following the instructions in <xref
                linkend="testbench.headless.running"/>. Then, start PhantomJS using the
                following command:
            </para>
            
            <programlisting><?pocket-size 65% ?><![CDATA[phantomjs --webdriver=8080 \
          --webdriver-selenium-grid-hub=http://127.0.0.1:4444]]></programlisting>
        	
            <para>
                The above will start PhantomJS in the WebDriver mode and register it with
                a grid hub running at <literal>127.0.0.1:4444</literal>. After this,
                running tests in the grid is as easy as passing
                <methodname>DesiredCapabilities.phantomjs()</methodname> to the
                <literal>RemoteWebDriver</literal> constructor.
            </para>

            <programlisting><?pocket-size 75% ?><![CDATA[setDriver(new RemoteWebDriver(
        DesiredCapabilities.phantomjs()));]]></programlisting>
        </section>
    </section>

    <section xml:id="testbench.bdd">
        <title>Behavior-Driven Development</title>

        <para>
            
        </para>
    </section>

    <section xml:id="testbench.known-issues">
        <title>Known Issues</title>

        <para>
            This section provides information and instructions on a few features that are known
            to be difficult to use or need modification to work.
        </para>

        <section xml:id="testbench.known-issues.loginform">
            <title>Testing the LoginForm</title>

            <para>
                Please note that, as of Vaadin 7, <classname>LoginForm</classname> has
                been deprecated and should no longer be used. This section is here to
                inform those still using Vaadin 6.x and testing with Vaadin TestBench.
            </para>

            <para>
                Replaying interactions in the <classname>LoginForm</classname> component
                is somewhat tricky because the identifier of the <literal>iframe</literal>
                element changes every time the application is restarted, so it can not be
                used for selecting it. The use of an iframe element means that recordings
                have to select the target frame before fields can be correctly identified.
            </para>

            <section xml:id="testbench.known-issues.loginform.junit">
                <title>Selecting a Frame in JUnit Code</title>

                <para>
                    Selecting the correct frame in JUnit code by index number can be done
                    as follows:
                </para>

                <programlisting><![CDATA[// Select frame by its 0-based index
getDriver().switchTo().frame(2);]]></programlisting>

                <para>
                    Or by the XPath with:
                </para>

                <programlisting><![CDATA[WebElement frame = getDriver().
    findElement(By.xpath("//id('login')//iframe"));
getDriver().switchTo().frame(frame);]]></programlisting>
            </section>
        </section>

        <section xml:id="testbench.known-issues.firefox-mac">
            <title>Running Firefox Tests on Mac OS X</title>

            <para>
                Firefox needs to have focus in the main window for any focus events to be
                triggered. This sometimes causes problems if something interferes with the
                focus. For example, a <classname>TextField</classname> that has an input
                prompt relies on the JavaScript <methodname>onFocus()</methodname> event
                to clear the prompt when the field is focused.
            </para>

            <para>
                The problem occurs when OS X considers the Java process of an application
                using TestBench (or the node service) to have a native user interface
                capability, as with AWT or Swing, even when they are not used. This causes
                the focus to switch from Firefox to the process using TestBench, causing
                tests requiring focus to fail. To remedy this problem, you need to start
                the JVM in which the tests are running with the
                <parameter>-Djava.awt.headless=true</parameter> parameter to disable the
                user interface capability of the Java process.
            </para>

            <para>
                Note that the same problem is present also when debugging tests with
                Firefox. We therefore recommend using Chrome for debugging tests, unless
                Firefox is necessary.
            </para>
        </section>
    </section>
</chapter>

<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:nil
sgml-shorttag:nil
sgml-namecase-general:nil
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:4
sgml-indent-data:t
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:("/etc/sgml/catalog" "/usr/share/xemacs21/xemacs-packages/etc/psgml-dtds/CATALOG")
sgml-local-ecat-files:("ECAT" "~/sgml/ECAT" "/usr/share/sgml/ECAT" "/usr/local/share/sgml/ECAT" "/usr/local/lib/sgml/ECAT")
End:
-->
